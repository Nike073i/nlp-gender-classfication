{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2f816b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./venv/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: openpyxl in ./venv/lib/python3.12/site-packages (3.1.5)\n",
      "Requirement already satisfied: scikit-learn in ./venv/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.12/site-packages (2.2.5)\n",
      "Requirement already satisfied: matplotlib in ./venv/lib/python3.12/site-packages (3.10.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: et-xmlfile in ./venv/lib/python3.12/site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./venv/lib/python3.12/site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./venv/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./venv/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.12/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.12/site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./venv/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./venv/lib/python3.12/site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./venv/lib/python3.12/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas openpyxl scikit-learn numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "751b3eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, accuracy_score, classification_report\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from natasha import NewsEmbedding\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from functools import partial\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23d8f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_extractor(df_num, vector_embeddings):\n",
    "    vect_columns = [f\"vect_{i}\" for i in range(vector_embeddings.shape[1])]\n",
    "    df_vect = pd.DataFrame(vector_embeddings, columns=vect_columns)\n",
    "    num_columns = df_num.columns\n",
    "\n",
    "    combined_df = pd.concat([df_num.reset_index(drop=True), df_vect], axis=1)\n",
    "    \n",
    "    def get_num(X):\n",
    "        return X[num_columns].values\n",
    "    \n",
    "    def get_vect(X):\n",
    "        return X[vect_columns].values\n",
    "    \n",
    "    return combined_df, get_num, get_vect\n",
    "\n",
    "\n",
    "def text_to_vector(emb, lemmas_doc, dimm=300): \n",
    "    vectors = []\n",
    "    for sentence in lemmas_doc:\n",
    "        for word in sentence:\n",
    "            if word in emb:\n",
    "                vectors.append(emb[word])\n",
    "    \n",
    "    if not vectors:\n",
    "        return np.zeros(dimm)\n",
    "    \n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "\n",
    "class PipelineBuilder:\n",
    "    default_selector_k = 10\n",
    "\n",
    "    def __init__(self, model_factory, get_num):\n",
    "        self.get_num = get_num\n",
    "        self.model_factory = model_factory\n",
    "        self.include_std = False\n",
    "        self.include_kbest = False\n",
    "        self.vector_model_factory = None\n",
    "        self.get_vect = None\n",
    "        self.ensemble = None\n",
    "\n",
    "    def use_std(self):\n",
    "        self.include_std = True\n",
    "        return self\n",
    "    \n",
    "    def use_kbest(self):\n",
    "        self.include_kbest = True\n",
    "        return self\n",
    "    \n",
    "    def use_vect(self, get_vect, model_factory=None, ensemble=None):\n",
    "        self.vector_model_factory = model_factory\n",
    "        self.get_vect = get_vect\n",
    "        self.ensemble = ensemble\n",
    "        return self\n",
    "    \n",
    "    def __build_num_pipeline(self):\n",
    "        steps = [\n",
    "            ('get_num', FunctionTransformer(self.get_num))\n",
    "        ]\n",
    "        \n",
    "        if self.include_std:\n",
    "            steps.append(('scaler', StandardScaler()))\n",
    "            \n",
    "        if self.include_kbest:\n",
    "            steps.append(('selector', SelectKBest(k=PipelineBuilder.default_selector_k, score_func=mutual_info_classif)))\n",
    "            \n",
    "        return Pipeline(steps)\n",
    "    \n",
    "    def __build_ensemble(self, num_model, vect_model):\n",
    "        model_factory, params = self.ensemble\n",
    "        estimators = [\n",
    "            ('vect_model', vect_model),\n",
    "            ('num_model', num_model),\n",
    "        ]   \n",
    "        return model_factory(estimators=estimators, **params)\n",
    "\n",
    "    def build(self):\n",
    "        num_pipeline = self.__build_num_pipeline()\n",
    "\n",
    "        # Только признаки\n",
    "        if not self.get_vect:\n",
    "            num_pipeline.steps.append(\n",
    "                ('model', self.model_factory())\n",
    "            )\n",
    "            return num_pipeline\n",
    "        \n",
    "        vect_pipeline = Pipeline([\n",
    "            ('get_vect', FunctionTransformer(self.get_vect, validate=False))\n",
    "        ])\n",
    "        \n",
    "        # Общая модель для признаков\n",
    "        if not self.vector_model_factory:\n",
    "            return Pipeline([\n",
    "                ('features', FeatureUnion([\n",
    "                    ('num', num_pipeline),\n",
    "                    ('vect', vect_pipeline)\n",
    "                ])),\n",
    "                ('model', self.model_factory())\n",
    "            ])\n",
    "        \n",
    "        # Разные модели\n",
    "        num_model = Pipeline(num_pipeline.steps + [('model', self.model_factory())])\n",
    "        vect_model = Pipeline(vect_pipeline.steps + [('model', self.vector_model_factory())])\n",
    "        \n",
    "        return self.__build_ensemble(num_model, vect_model)\n",
    "    \n",
    "def create_accuracy(k_name, k_min, penalty_factor):    \n",
    "    def accuracy_with_penalty(estimator, X, y):\n",
    "        y_pred = estimator.predict(X)\n",
    "        base_score = accuracy_score(y, y_pred)\n",
    "        k = estimator.get_params().get(k_name, None)\n",
    "        penalty = k / X.shape[1]\n",
    "\n",
    "        if k > k_min:\n",
    "            penalty = (1 - penalty_factor) ** (k - k_min)\n",
    "            return base_score * penalty\n",
    "        return base_score\n",
    "    return accuracy_with_penalty\n",
    "\n",
    "def get_best_models(pipeline_grids, X_train, y_train):\n",
    "    results = []\n",
    "    total = len(pipeline_grids)\n",
    "    count = 0\n",
    "    for (name, pipeline, grid, scoring) in pipeline_grids:\n",
    "        print (f\"{count + 1} / { total }\")\n",
    "        grid_search = GridSearchCV(pipeline, grid, cv=5, n_jobs=-1, scoring=scoring)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        results.append((name, grid_search))\n",
    "        count+=1\n",
    "\n",
    "    return results\n",
    "\n",
    "def evaluate_quality(y_pred, y_test):\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(f\"AUC = {roc_auc_score(y_test, y_pred)}\")\n",
    "\n",
    "def evaluate_models(models, X_test, y_test):\n",
    "    for (name, model) in models:\n",
    "        print(f'--------------{name}--------------')\n",
    "        print(f'model parameters: {model.best_params_}')\n",
    "\n",
    "        if hasattr(model.best_estimator_, 'named_steps'):\n",
    "            if 'selector' in model.best_estimator_.named_steps:\n",
    "                print(f'selected features: {model.best_estimator_.named_steps['selector'].get_feature_names_out()}')\n",
    "\n",
    "            elif 'model' in model.best_estimator_.named_steps and hasattr(model.best_estimator_.named_steps['model'], 'feature_importances_'):\n",
    "                feature_importances = model.best_estimator_.named_steps['model'].feature_importances_\n",
    "                features_df = pd.DataFrame({'feature': [ f\"x{i}\" for i in range (model.best_estimator_.named_steps['model'].n_features_in_)], 'importance': feature_importances})\n",
    "                features_df = features_df.sort_values(by='importance', ascending=False)\n",
    "                print(features_df.head(10))\n",
    "\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        evaluate_quality(y_pred, y_test)\n",
    "\n",
    "def prepare_input(df, test_size, emb, feature_cols, target_col):\n",
    "    vectors = np.vstack(df['lemm_sentences'].apply(partial(text_to_vector, emb)).values)\n",
    "    X, get_num, get_vect = create_feature_extractor(df[feature_cols], vectors)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, df[target_col], test_size=test_size, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test, get_num, get_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d8d1753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Unnamed: 0",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Текст",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Пол",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "length",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mean_usage_[URL]",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mean_usage_[ADDRESS]",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mean_usage_[NUMBER]",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean_usage_[QUOTE]",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean_usage_[PUNCEM]",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean_usage_[REMOVED]",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mean_usage_,",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean_usage_!",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mean_usage_?",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mean_usage_:",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean_usage_-",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean_usage_(",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean_usage_)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean_usage_ADJ",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean_usage_ADP",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean_usage_ADV",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean_usage_NOUN",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean_usage_DET",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean_usage_NUM",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean_usage_VERB",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean_usage_PART",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean_usage_PRON",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean_usage_SCONJ",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mean_usage_sentence_length",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean_token_length",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lemm_sentences",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sentences_count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "027a1467-0a7e-4c96-a2db-b5a1485fd2bb",
       "rows": [
        [
         "0",
         "Сегодня, моё беззаботное детство и суетливое настоящее встретились лицом к лицу. В свои шестнадцать - я становлюсь трудоголиком. За частую многим из нас, просто хочется на минутку выйти из этого мира. Погрузится, нырнуть в тихую пучину воспоминаний. Но эта минута не часто заглядывает к нам дом . Она может позвонить в дверь вашей души - взволновав её. Минута может остаться у вас на пороге и не проходить дальше, волнуя вас ещё больше. Но моя минута, мои шестьдесят секунд, всё-таки проведали, нуждающуюся в умиротворении.  Пожалуй все мои дедушки и бабушки очень творческие люди. Одна неувядающий журналист, другая пишет стопками стихи .Дед был фотографом, и его жилище  - это просто арт-квартира с множеством музыкальных инструментов.  В детстве я проводила долгие часы за этими волшебными предметами. В три года, я конечно не умела играть на гитаре, пианино или саксофоне. Но меня всегда манили все инструменты, которые были в арт-доме.. Вдоволь побренчав на всём вокруг,мой взгляд попадал на семиструнную.. Я тихонько садилась к ней рядом и маленькими детскими пальчиками играла всегда одну мелодию, которую сама сочинила, в том далёком возрасте. Я так любила этот мотив. Вместе с ним звучали все нотки моей души, танцевали  все мысли моей беззаботной головы. Проснувшись днём  9 апреля,  я устала. Да да, первый раз в жизни, я устала только-только проснувшись. Наверное у каждого такое было. Не знала куда идти - сердце показывало дорогу.  Люблю Сашин дом. Люблю готовить в нём . После прекрасного ужина приготовленного вместе, четырьмя руками одовременно, мы тихо прошли в комнату красных закатов .  \"Это симфония, которую я придумал, что бы ты сладко засыпала\". Перебором,. из под Сашиных пальцев, тихонько выпорхнули те самые нотки. Это была та забытая мелодия, маленькой девочки-композитора. Музыка укрыла меня тёплым одеялом из нежных звуков струн. Невероятная спокойность распустилась в моей душе . Трудоголик Катя сдалась. Теперь, сердце моё пело, пело и тихо плакало от счастья. Ровно ту самую минуту.  Это гармония. Это наш очаг.",
         "0",
         "2062",
         "0",
         "0",
         "0.0",
         "0.02941176470588235",
         "0.05882352941176471",
         "0",
         "0.7647058823529411",
         "0",
         "0",
         "0.0",
         "0.2647058823529412",
         "0.0",
         "0.0",
         "0.5294117647058824",
         "0.02941176470588235",
         "0.5588235294117647",
         "2.323529411764706",
         "0.2352941176470588",
         "0.1176470588235294",
         "1.411764705882353",
         "0.1176470588235294",
         "0.2058823529411765",
         "0",
         "10.52941176470588",
         "6.893617021276595",
         "[[\"сегодня\", \"беззаботный\", \"детство\", \"суетливый\", \"настоящее\", \"встретиться\", \"лицо\", \"лицо\"], [\"свой\", \"шестнадцать\", \"становиться\", \"трудоголик\"], [\"часть\", \"многий\", \"просто\", \"хотеться\", \"минутка\", \"выйти\", \"мир\"], [\"погрузиться\", \"вернуть\", \"мужчина\", \"воспоминание\"], [\"минута\", \"часто\", \"заглядывать\", \"дом\"], [\"мочь\", \"позвонить\", \"дверь\", \"ваш\", \"душа\", \"взволновать\"], [\"минута\", \"мочь\", \"остаться\", \"дорога\", \"проходить\", \"далекий\", \"полный\"], [\"минута\", \"шестьдесят\", \"секунда\", \"все-таки\", \"провести\", \"нуждаться\", \"умиротворение\"], [\"пожаловать\", \"весь\", \"девушка\", \"бабушка\", \"очень\", \"творческий\", \"человек\"], [\"неувядающий\", \"журналист\", \"писать\", \"стопка\", \"стих\", \"дед\", \"фотография\", \"жилище\", \"это\", \"просто\", \"арт-квартира\", \"множество\", \"музыкальный\", \"инструмент\"], [\"детство\", \"проводить\", \"долгий\", \"час\", \"волшебный\", \"пределами\"], [\"год\", \"умереть\", \"играть\", \"гитара\", \"пианино\", \"саксофон\"], [\"ранить\", \"весь\", \"инструмент\", \"который\", \"арт-дом\"], [\"вдоль\", \"побренчать\", \"весь\", \"вокруг\", \"взгляд\", \"попасть\", \"семиструнный\"], [\"тихонько\", \"садиться\", \"рядом\", \"маленькая\", \"детский\", \"пальчик\", \"играть\", \"мелодия\", \"который\", \"починить\", \"далеко\", \"возраст\"], [\"любить\", \"мотив\"], [\"вместе\", \"звучать\", \"весь\", \"носок\", \"душа\", \"танцевать\", \"весь\", \"мысль\", \"безработный\", \"голова\"], [\"проснуться\", \"день\", \"устать\"], [\"первый\", \"жизнь\", \"устать\", \"только-только\", \"проснуться\"], [\"наверное\", \"каждый\"], [\"знать\", \"идти\", \"сердце\", \"показывать\", \"дорога\"], [\"любить\", \"машина\", \"дом\"], [\"любить\", \"готовить\", \"оно\"], [\"прекрасный\", \"ужин\", \"приготовить\", \"вместе\", \"четыре\", \"рука\", \"одновременно\", \"тихо\", \"пройти\", \"комната\", \"красный\", \"закат\"], [\"переворот\", \"машина\", \"палец\", \"тихонько\", \"выпорхнуть\", \"самый\", \"носок\"], [\"это\", \"забывать\", \"мелодия\", \"маленький\", \"девочка-композитор\"], [\"музыка\", \"украсть\", \"теплый\", \"одеяло\", \"нежный\", \"звук\", \"стоун\"], [\"невероятный\", \"способность\", \"распуститься\", \"душа\"], [\"трудоголик\", \"катя\", \"сделать\"], [\"сердце\", \"дело\", \"дело\", \"тихо\", \"плакать\", \"счастие\"], [\"ровно\", \"самый\", \"минута\"], [\"это\", \"гармония\"], [\"это\", \"наш\"]]",
         "34"
        ],
        [
         "3",
         "Спасибо большое Саше за помощь при регистрации в ЖЖ. Этот выбор имени, темы... В итоге мне очень нравится результат . Само понимание того, что здесь существует полная свобода самовыражения толкает на разные приятные размышления. В итоге, сильным образом на меня повлиял выбор вида моей страницы. Благодаря такой тематике, расскажу о выставке картин на Цвиллинга. В первую очередь, мне хочется поделиться с недавними странными чувствами сопротивления двух меня( как это  часто бывает) , которые столкнулись лицом к лицу с работами интересного душевного друга - Сальвадора Дали. Обычно на такие выставки собираешься очень долго. Морально подготовится к этому стоит, настроится на особенный лад. Дорога туда становится удивительной погоней за собственными мыслями, которые ведут тебя прямо к цели - новым размышлениям. Может здесь и таится бесконечность? На самом деле, я ждала от Дали гораздо большего. Однако, я зря обвиняю его. Работы Сальвадора, находящиеся в Челябинске - это собрание картин, которые живут в частной коллекции одного человека. Простого человека, который видимо смотрит на мир по-другому. Или, откровенно говоря, у него просто не хватило денег на картины, более похожие на  творчество Дали. Это трудно выразить, но я почему то уверена, что Сальвадор со мной бы согласился.",
         "0",
         "1303",
         "0",
         "1",
         "0.0",
         "0.0",
         "0.05882352941176471",
         "0",
         "1.058823529411765",
         "0",
         "1",
         "0.0",
         "0.2352941176470588",
         "0.05882352941176471",
         "0.05882352941176471",
         "1.058823529411765",
         "0.05882352941176471",
         "1.117647058823529",
         "2.764705882352941",
         "0.05882352941176471",
         "0.0",
         "1.764705882352941",
         "0.1176470588235294",
         "0.4117647058823529",
         "0",
         "13.17647058823529",
         "7.024",
         "[[\"спасибо\", \"большой\", \"ваш\", \"помощь\", \"регистрация\"], [\"выбор\", \"имя\", \"тема\"], [\"итоге\", \"очень\", \"нравиться\", \"результат\"], [\"понимание\", \"существовать\", \"полный\", \"свобода\", \"самовыражение\", \"толкать\", \"разный\", \"приятный\", \"размышление\"], [\"итоге\", \"сильный\", \"образ\", \"повлиять\", \"выбор\", \"вид\", \"страница\"], [\"благодаря\", \"тематика\", \"рассказать\", \"выставка\", \"мартин\", \"цвиллинг\"], [\"первый\", \"очередь\", \"хотеться\", \"поделиться\", \"недавний\", \"странный\", \"чувство\", \"сопротивление\", \"это\", \"часто\", \"бывать\", \"который\", \"столкнуться\", \"лицо\", \"лицо\", \"работать\", \"интересно\", \"душевный\", \"друг\", \"сальватор\", \"дать\"], [\"обычно\", \"выставка\", \"собираться\", \"очень\", \"долго\"], [\"нормально\", \"подготовиться\", \"это\", \"стоить\", \"настроиться\", \"особенный\", \"рад\"], [\"дорога\", \"туда\", \"становиться\", \"удивительно\", \"погоня\", \"собственный\", \"мысль\", \"который\", \"вести\", \"прямо\", \"цель\", \"новый\", \"размышление\"], [\"мочь\", \"бояться\", \"бесконечность\"], [\"дело\", \"ждать\", \"дать\", \"гораздо\", \"больший\"], [\"однако\", \"зря\", \"обвинять\"], [\"работа\", \"сальватор\", \"находиться\", \"это\", \"собрание\", \"мартин\", \"который\", \"жить\", \"частный\", \"коллекция\", \"человек\"], [\"простой\", \"человек\", \"который\", \"видимо\", \"смотреть\", \"мир\", \"по-другому\"], [\"откровенно\", \"говорить\", \"просто\", \"хватить\", \"деньга\", \"картина\", \"похожий\", \"торжество\", \"дать\"], [\"это\", \"трудный\", \"выразить\", \"почему\", \"уверить\", \"сальватор\", \"согласиться\"]]",
         "17"
        ],
        [
         "4",
         "Ох. Я заболела. Ну и пускай :) Давно со мной такого не случалось уже. Не поехала на курсы в универ, но честно пыталась. Преградой послужило то, что я попала под ливень, но, дойдя до метро, оказалось, что у меня карточка не заряжена, а денег я с собой не взяла... Пришлось возвращаться домой. Зато я поехала в театр. Оперетты! Смотрели спектакль под названием \"Весёлая Вдова\"(правда  веселое  название?:)). Мне в принципе понравилось. Познакомились с одним умным и хорошим дедулей. Он пригласил нас в театр, даже предоставил выбор!! Дал свой номер телефона и попросил записать наш. Он какой-то учёный. Работает в Академии Наук Российской Федерации. Мне интересно, честно :) Спрашивал нас куда мы будем поступать, а сначала вообще принял за студенток. Хехе. У него есть какая-то знакомая, которая знает английский и имеет большую библиотеку, как он сказал, предложил нам её помощь при поступлении в университет :) Надо почаще в театр ходить. Всё-таки там только интеллигентные люди, с которыми приятно пообщаться и главное есть о чём.",
         "0",
         "1040",
         "0",
         "0",
         "0.0",
         "0.04545454545454546",
         "0.09090909090909091",
         "0",
         "0.6363636363636364",
         "1",
         "1",
         "0.0",
         "0.1363636363636364",
         "0.04545454545454546",
         "0.0",
         "0.4545454545454545",
         "0.0",
         "0.4090909090909091",
         "1.363636363636364",
         "0.1818181818181818",
         "0.0",
         "1.409090909090909",
         "0.09090909090909091",
         "0.09090909090909091",
         "0",
         "8.636363636363637",
         "7.303370786516854",
         "[[\"ох\"], [\"заболеть\"], [\"пускай\"], [\"давно\", \"случаться\"], [\"поехать\", \"курс\", \"оливер\", \"честно\", \"пытаться\"], [\"преграда\", \"поступить\", \"попасть\", \"живешь\", \"дождь\", \"метро\", \"оказаться\", \"карточка\", \"зарядить\", \"деньга\", \"взять\"], [\"прийтись\", \"возвращаться\", \"домой\"], [\"зато\", \"поехать\", \"театр\"], [\"оперетта\"], [\"смотреть\", \"спектакль\", \"название\", \"правда\", \"веселый\", \"название\"], [\"принцип\", \"понравиться\"], [\"познакомиться\", \"умный\", \"хороший\", \"дедуля\"], [\"пригласить\", \"театр\", \"предоставить\", \"выбор\"], [\"дать\", \"свой\", \"номер\", \"телефон\", \"попросить\", \"записать\", \"наш\"], [\"какой-то\", \"ученый\"], [\"работать\", \"академия\", \"наука\", \"российский\", \"федерация\"], [\"интересный\", \"честно\"], [\"спрашивать\", \"поступать\", \"сначала\", \"вообще\", \"принять\", \"студент\"], [\"какой-то\", \"знакомый\", \"который\", \"знать\", \"английский\", \"иметь\", \"больший\", \"библиотека\", \"сказать\", \"предложить\", \"помощь\", \"поступление\", \"университет\"], [\"почаще\", \"театр\", \"ходить\"], [\"все-таки\", \"интеллигентный\", \"человек\", \"который\", \"приятный\", \"общаться\", \"главный\"]]",
         "22"
        ],
        [
         "10",
         "Двое не спят. Двое дымят папиросу любви.  Им хорошо. Станем ли мы нарушать их покой?   Только летом цунами впечатлений покрывает наш город. Я вчера вдруг поняла, что наконец наступило то самое лето. И буря эмоций нахлестывает как всегда в это время года больше, чем в остальные. Горячей воды опять нет на  двадцать дней. А группа Сплин опять собралась в Саду Эрмитаж, чтобы наполнить это лето своим настроением. Сашка Васильев и его группа...  Их музыка для меня началась наверно с \"Орбита без сахара\" (это, кажется, 1998). Это второй концерт. В том самом Саду Эрмитаж, где я прежде не бывала. Я так много слышала про концерт 2006 года и надеялась, что будет дождь и вчера. Но повторений не бывает. Погода была чудесная. Сашка был великолепен, ребята старались очень, даже Леша (ударник) сломал палец. О как бывает!  Бедняга..  Я так и сказала, что хочу, чтобы на бис спели \"Мы сидели и курили\", \"Тебе это снится\" и \" Маяк\", так оно и получилось.  Именно этот концерт был тем самым концертом, который я ждала от Сплина. Совсем не так, как в Б1. Совсем не скучно. Атмосфера! Вспоминалось детство, почему-то папа и счастье. Устремляла взгляд в небо и мечтала о том, чтобы все-все, что задумалось, исполнилось.  Вы наверняка так же, как и я, в разных местах чувствуете себя по-разному. Где-то более кв своей тарелке, где-то менее. Где-то вы те, кем вы являетесь, где-то меняетесь, потому что так просит место, а чаще люди там обитающие. Вчера я была в той атмосфере, где я оставалась той, кем я являюсь. И не было никаких факторов, заставляющих вести себя неестественно. Как же я люблю, когда все именно так!    photo by  cartmany Спасибо!   Если б я знал, как это трудно - уснуть одному, Если б я знал, что меня ждет, я бы прыгнул в окно. А так - все идет, скучно в Москве и дождливо в Крыму.. И все хорошо, и эти двое уснули давно..",
         "0",
         "1846",
         "0",
         "1",
         "0.02857142857142857",
         "0.1142857142857143",
         "0.1142857142857143",
         "1",
         "1.028571428571428",
         "1",
         "1",
         "0.0",
         "0.2571428571428571",
         "0.05714285714285714",
         "0.05714285714285714",
         "0.4285714285714285",
         "0.0",
         "0.4857142857142857",
         "1.514285714285714",
         "0.1714285714285714",
         "0.1428571428571428",
         "1.314285714285714",
         "0.08571428571428572",
         "0.2285714285714286",
         "0",
         "10.51428571428571",
         "6.283870967741936",
         "[[\"двое\", \"спать\"], [\"двое\", \"дым\", \"папироса\", \"любовь\"], [\"хороший\"], [\"стать\", \"нарушать\", \"покой\"], [\"лето\", \"впечатление\", \"покрывать\", \"наш\", \"город\"], [\"вчера\", \"понять\", \"наступить\", \"самый\", \"лето\"], [\"буря\", \"эмоция\", \"нахлестывать\", \"это\", \"время\", \"год\", \"остальной\"], [\"горячий\", \"вода\", \"двадцать\", \"день\"], [\"группа\", \"селина\", \"собраться\", \"сад\", \"эрмитаж\", \"напомнить\", \"это\", \"лето\", \"свой\", \"настроение\"], [\"саша\", \"васильев\", \"группа\"], [\"музыка\", \"начаться\", \"наверно\", \"это\", \"казаться\"], [\"это\", \"второй\", \"концерт\"], [\"сад\", \"эрмитаж\", \"прежде\", \"бывать\"], [\"слышать\", \"концерт\", \"надеяться\", \"дождь\", \"вчера\"], [\"повторение\", \"бывать\"], [\"погода\", \"чудесный\"], [\"саша\", \"великолепный\", \"ребята\", \"стараться\", \"очень\", \"лена\", \"ударить\", \"сломать\", \"палец\"], [\"бывать\"], [\"бедняга\"], [\"сказать\", \"хотеть\", \"рис\", \"спать\", \"оно\", \"получиться\"], [\"именно\", \"концерт\", \"самый\", \"концерт\", \"который\", \"ждать\", \"спин\"], [\"б\", \"1\"], [\"скучный\"], [\"атмосфера\"], [\"вспоминаться\", \"детство\", \"почему-то\", \"папа\", \"счастие\"], [\"устремлять\", \"взгляд\", \"небо\", \"мечтать\", \"весь-весь\", \"задуматься\", \"исполниться\"], [\"наверняка\", \"разный\", \"место\", \"чувствовать\", \"по-разному\"], [\"где-то\", \"свой\", \"тарелка\", \"где-то\", \"менее\"], [\"где-то\", \"являться\", \"где-то\", \"меняться\", \"просить\", \"место\", \"частый\", \"человек\", \"обитать\"], [\"вчера\", \"атмосфера\", \"оставаться\", \"являться\"], [\"никакой\", \"фактор\", \"заставлять\", \"вести\", \"естественно\"], [\"любить\", \"весь\", \"именно\", \"спасибо\"], [\"знать\", \"это\", \"трудный\", \"уснуть\", \"знать\", \"ждать\", \"прыгнуть\", \"окно\"], [\"весь\", \"идти\", \"скучно\", \"дождливый\", \"крыша\"], [\"весь\", \"хороший\", \"двое\", \"уснуть\", \"давно\"]]",
         "35"
        ],
        [
         "11",
         "Я вспомнила, что когда-то проходила уже этот тест. И уже тогда он меня довольно сильно удивил, выдав мне просто потрясающе похожую характеристику на меня саму. Тогда я как-то довольно спокойно к этому отнеслась. Сейчас я нашла у  meravigliosaaa  ссылку на этот тест и сделала его снова. Мне почему-то очень интересен такой тип тестов, да и вообще я детства обожаю заполнять всякие анкеты, участвовать в опросах и сама же узнавать побольше о себе, с чем-то соглашаться или с чем-то спорить. Как же мне нравится. Получился тот же результат, хотя вопросы были немного другими.  Я Есенин.  Есенин(Лирик)   Есенин чуствует себя в потоке времени, который несет его и из которого уйти нельзя, да и не хочется. В своем воображении он  легко отрывается от реальности ,  часто и   подолгу мечтает . Предметом его мечты может быть и идеальная любовь, и возможность открыть частную школу, и отправиться в захватывающее путешествие. Мечтать он может и о хорошей машине и о квартире, но это, скорее детское желание иметь свой “терем с балконом”. Много размышляет  о себе, о своих способностях, стремится понять себя. Иногда представители этого типа ищут в себе способности экстрасенса, анализируют свои возможности воздействия на людей. Легко поддается внушению, легковерен. Часто  колеблется в выборе  того или иного решения. Есенин  хорошо чувствует надвигающуюся опасность  и вовремя старается предупредить ее. Умеет оттянуть время решающего обьяснения, и время назревающего конфликта. Он изменит тактику и постарается взять ситуацию в свои руки так, чтобы подготовиться к неприятному для себя исходу   (например,найдет себе другое “крыло” или другой источник дохода.) Прошлое  всегда  оставляет  в нем  глубокий след ,  если оно   связано с отрицательными переживаниями , в то время как положительные эмоции   - лишь мимолетную отметку. Есенин-  художник настроения : какую картину нарисует- так тому и быть. Настроение- инструмент его воздействия на окружающих. Настроением он может “одарить”, а может и наказать. Настроение для Есенина- это еще и способ манипулировать окружающими. Мало кто умеет так  творчески скандалить , как Есенин. Собственных чуств не скрывает, совершенно  непринужденно может на людях рассмеяться и расплакаться . Периодически Есенин может проявлять себя как  зачинщик конфликтов - способ, необходимый ему для выяснения собственного положения в системе отношений. Есенин никак не попадет в разряд активных, деловых, энергичных людей. Ему с трудом дается деловая активность,  может увлечься чем- то  , составить план, например обучения на заочном факультете, но через несколько занятий  не выдержать напряжения и бросить .  Так кончаются большинство намерений, продиктованных разумом, а не   сердцем.  Человеку этого типа трудно поддерживать порядок в квартире постоянно   - он может полениться вовремя вымыть посуду. Попросив, например, сестру помочь убраться в квартире, уже через час, не сделав и половины работы, приглашает “поесть что-нибудь вкусненькое”, забросив дела на пол-дороге. Ему  трудно поддерживать порядок  также и  в финансовых делах . Деньги могут валяться в самых неподходящих местах, покупки делаются часто стихийно, даже если они крупные. Может тратить деньги на ненужные безделушки, если они имеют  изысканный  вид: ими может оказаться заставленной вся квартира. Это могут быть прелестные статуэтки, импортные детские игрушки, ажурные салфетки. Есенин  не лидер , а всегда ведомый. Проявление волевых усилий для него   - тяжелая задача.  Как никто другой, Есенин умеет найти болевые точки и надавить на них, чтобы получить желаемое. Тест",
         "0",
         "3587",
         "0",
         "0",
         "0.0",
         "0.1",
         "0.0",
         "1",
         "1.2",
         "0",
         "0",
         "0.05",
         "0.375",
         "0.05",
         "0.05",
         "0.95",
         "0.0",
         "0.9",
         "3.225",
         "0.175",
         "0.025",
         "2.35",
         "0.075",
         "0.25",
         "1",
         "14.775",
         "7.376175548589342",
         "[[\"вспомнить\", \"когда-то\", \"проходить\", \"тест\"], [\"довольно\", \"сильно\", \"удивить\", \"выдать\", \"просто\", \"потрясающе\", \"похоже\", \"характеристика\"], [\"как-то\", \"довольно\", \"спокойно\", \"это\", \"отнестись\"], [\"найти\", \"ссылка\", \"тест\", \"сделать\", \"снова\"], [\"почему-то\", \"очень\", \"интересный\", \"тип\", \"тесто\", \"вообще\", \"детства\", \"обожать\", \"заполнить\", \"всякий\", \"ангел\", \"участвовать\", \"опрос\", \"узнать\", \"большой\", \"что-то\", \"соглашаться\", \"что-то\", \"спорить\"], [\"нравиться\"], [\"получиться\", \"результат\", \"хотя\", \"вопрос\", \"немного\"], [\"селина\"], [\"селина\", \"лири\", \"селина\", \"чувствовать\", \"поток\", \"время\", \"который\", \"нести\", \"который\", \"уйти\", \"хотеться\"], [\"свой\", \"воображение\", \"легко\", \"открываться\", \"реальность\", \"часто\", \"помочь\", \"мечта\"], [\"предмет\", \"мечта\", \"мочь\", \"идеальный\", \"любовь\", \"возможность\", \"открыть\", \"частный\", \"школа\", \"отправиться\", \"захватывать\", \"путешествие\"], [\"мечтать\", \"мочь\", \"хороший\", \"машина\", \"квартира\", \"это\", \"скорый\", \"детский\", \"желание\", \"иметь\", \"свой\"], [\"размышлять\", \"свой\", \"способность\", \"встретиться\", \"понять\"], [\"представитель\", \"тип\", \"искать\", \"способность\", \"экстрасенс\", \"анализировать\", \"свой\", \"возможность\", \"воздействие\", \"человек\"], [\"легко\", \"продаваться\", \"внушение\", \"легковерный\"], [\"часто\", \"колебаться\", \"выбор\", \"иной\", \"решение\"], [\"селина\", \"чувствовать\", \"надвигаться\", \"опасность\", \"вовремя\", \"стараться\", \"предупредить\"], [\"уметь\", \"тянуть\", \"время\", \"решающий\", \"объяснение\", \"время\", \"назревающего\", \"конфликт\"], [\"изменить\", \"тактика\", \"постараться\", \"взять\", \"ситуация\", \"свой\", \"рука\", \"подготовиться\", \"неприятный\", \"исходить\", \"например\", \"найти\", \"источник\", \"доход\"], [\"прошлое\", \"оставлять\", \"нем\", \"глубокий\", \"след\", \"оно\", \"связать\", \"отрицательный\", \"переживание\", \"время\", \"положительный\", \"эмоция\", \"лишь\", \"мимолетный\", \"отметка\"], [\"есенин-\", \"художник\", \"настроение\", \"картина\", \"нарисует-\"], [\"настроение-\", \"инструмент\", \"воздействие\", \"окружающие\"], [\"настроение\", \"мочь\", \"мочь\", \"наказать\"], [\"настроение\", \"есенина-\", \"это\", \"способ\", \"манипулировать\", \"окружающие\"], [\"мало\", \"уметь\", \"творческий\", \"скандалить\", \"селина\"], [\"собственный\", \"чувство\", \"скрывать\", \"совершенно\", \"непринужденно\", \"мочь\", \"человек\", \"рассмеяться\", \"расплакаться\"], [\"периодически\", \"селина\", \"мочь\", \"проявить\", \"зачинщик\", \"конфликт\", \"способ\", \"необходимый\", \"выяснение\", \"собственный\", \"положение\", \"система\", \"отношение\"], [\"селина\", \"никак\", \"попасть\", \"разряд\", \"активный\", \"деловой\", \"энергичный\", \"человек\"], [\"трудно\", \"сдаваться\", \"деловой\", \"активность\", \"мочь\", \"увлечься\", \"чем-\", \"составить\", \"план\", \"например\", \"обучение\", \"заодно\", \"факультет\", \"несколько\", \"занятие\", \"выдержать\", \"напряжение\", \"бросить\"], [\"кончаться\", \"большинство\", \"намерение\", \"продиктовать\", \"разум\", \"сердце\"], [\"человек\", \"тип\", \"трудный\", \"поддерживать\", \"порядок\", \"квартира\", \"постоянно\", \"мочь\", \"пожениться\", \"вовремя\", \"выпить\", \"посуда\"], [\"попросить\", \"например\", \"сестра\", \"помочь\", \"убраться\", \"квартира\", \"час\", \"сделать\", \"половина\", \"работа\", \"приглашать\", \"бросить\", \"дело\", \"пол-дорога\"], [\"трудный\", \"поддерживать\", \"порядок\", \"также\", \"финансовый\", \"дело\"], [\"деньга\", \"мочь\", \"заняться\", \"самый\", \"неподходящий\", \"место\", \"покупка\", \"делаться\", \"часто\", \"стихийно\", \"крупный\"], [\"мочь\", \"тратить\", \"деньга\", \"денежный\", \"безделушка\", \"иметь\", \"изысканный\", \"вид\", \"мочь\", \"оказаться\", \"заставленной\", \"весь\", \"квартира\"], [\"это\", \"мочь\", \"прелестный\", \"статуэтка\", \"импортный\", \"детский\", \"игрушка\", \"дурной\", \"салфетка\"], [\"селина\", \"лидер\", \"ведомый\"], [\"проявление\", \"полевой\", \"усилие\", \"тяжелый\", \"задача\"], [\"никто\", \"селина\", \"уметь\", \"найти\", \"боевой\", \"точка\", \"задавать\", \"получить\", \"желать\"], [\"тест\"]]",
         "40"
        ]
       ],
       "shape": {
        "columns": 30,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Текст</th>\n",
       "      <th>Пол</th>\n",
       "      <th>length</th>\n",
       "      <th>mean_usage_[URL]</th>\n",
       "      <th>mean_usage_[ADDRESS]</th>\n",
       "      <th>mean_usage_[NUMBER]</th>\n",
       "      <th>mean_usage_[QUOTE]</th>\n",
       "      <th>mean_usage_[PUNCEM]</th>\n",
       "      <th>mean_usage_[REMOVED]</th>\n",
       "      <th>mean_usage_,</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_usage_DET</th>\n",
       "      <th>mean_usage_NUM</th>\n",
       "      <th>mean_usage_VERB</th>\n",
       "      <th>mean_usage_PART</th>\n",
       "      <th>mean_usage_PRON</th>\n",
       "      <th>mean_usage_SCONJ</th>\n",
       "      <th>mean_usage_sentence_length</th>\n",
       "      <th>mean_token_length</th>\n",
       "      <th>lemm_sentences</th>\n",
       "      <th>sentences_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Сегодня, моё беззаботное детство и суетливое н...</td>\n",
       "      <td>0</td>\n",
       "      <td>2062</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>1.411765</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0</td>\n",
       "      <td>10.529412</td>\n",
       "      <td>6.893617</td>\n",
       "      <td>[[\"сегодня\", \"беззаботный\", \"детство\", \"суетли...</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Спасибо большое Саше за помощь при регистрации...</td>\n",
       "      <td>0</td>\n",
       "      <td>1303</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0</td>\n",
       "      <td>1.058824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.764706</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0</td>\n",
       "      <td>13.176471</td>\n",
       "      <td>7.024000</td>\n",
       "      <td>[[\"спасибо\", \"большой\", \"ваш\", \"помощь\", \"реги...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ох. Я заболела. Ну и пускай :) Давно со мной т...</td>\n",
       "      <td>0</td>\n",
       "      <td>1040</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.409091</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>8.636364</td>\n",
       "      <td>7.303371</td>\n",
       "      <td>[[\"ох\"], [\"заболеть\"], [\"пускай\"], [\"давно\", \"...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Двое не спят. Двое дымят папиросу любви.  Им х...</td>\n",
       "      <td>0</td>\n",
       "      <td>1846</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>1</td>\n",
       "      <td>1.028571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.314286</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0</td>\n",
       "      <td>10.514286</td>\n",
       "      <td>6.283871</td>\n",
       "      <td>[[\"двое\", \"спать\"], [\"двое\", \"дым\", \"папироса\"...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Я вспомнила, что когда-то проходила уже этот т...</td>\n",
       "      <td>0</td>\n",
       "      <td>3587</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>2.350000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>14.775000</td>\n",
       "      <td>7.376176</td>\n",
       "      <td>[[\"вспомнить\", \"когда-то\", \"проходить\", \"тест\"...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        Текст  Пол  length  \\\n",
       "Unnamed: 0                                                                   \n",
       "0           Сегодня, моё беззаботное детство и суетливое н...    0    2062   \n",
       "3           Спасибо большое Саше за помощь при регистрации...    0    1303   \n",
       "4           Ох. Я заболела. Ну и пускай :) Давно со мной т...    0    1040   \n",
       "10          Двое не спят. Двое дымят папиросу любви.  Им х...    0    1846   \n",
       "11          Я вспомнила, что когда-то проходила уже этот т...    0    3587   \n",
       "\n",
       "            mean_usage_[URL]  mean_usage_[ADDRESS]  mean_usage_[NUMBER]  \\\n",
       "Unnamed: 0                                                                \n",
       "0                          0                     0             0.000000   \n",
       "3                          0                     1             0.000000   \n",
       "4                          0                     0             0.000000   \n",
       "10                         0                     1             0.028571   \n",
       "11                         0                     0             0.000000   \n",
       "\n",
       "            mean_usage_[QUOTE]  mean_usage_[PUNCEM]  mean_usage_[REMOVED]  \\\n",
       "Unnamed: 0                                                                  \n",
       "0                     0.029412             0.058824                     0   \n",
       "3                     0.000000             0.058824                     0   \n",
       "4                     0.045455             0.090909                     0   \n",
       "10                    0.114286             0.114286                     1   \n",
       "11                    0.100000             0.000000                     1   \n",
       "\n",
       "            mean_usage_,  ...  mean_usage_DET  mean_usage_NUM  \\\n",
       "Unnamed: 0                ...                                   \n",
       "0               0.764706  ...        0.235294        0.117647   \n",
       "3               1.058824  ...        0.058824        0.000000   \n",
       "4               0.636364  ...        0.181818        0.000000   \n",
       "10              1.028571  ...        0.171429        0.142857   \n",
       "11              1.200000  ...        0.175000        0.025000   \n",
       "\n",
       "            mean_usage_VERB  mean_usage_PART  mean_usage_PRON  \\\n",
       "Unnamed: 0                                                      \n",
       "0                  1.411765         0.117647         0.205882   \n",
       "3                  1.764706         0.117647         0.411765   \n",
       "4                  1.409091         0.090909         0.090909   \n",
       "10                 1.314286         0.085714         0.228571   \n",
       "11                 2.350000         0.075000         0.250000   \n",
       "\n",
       "            mean_usage_SCONJ  mean_usage_sentence_length  mean_token_length  \\\n",
       "Unnamed: 0                                                                    \n",
       "0                          0                   10.529412           6.893617   \n",
       "3                          0                   13.176471           7.024000   \n",
       "4                          0                    8.636364           7.303371   \n",
       "10                         0                   10.514286           6.283871   \n",
       "11                         1                   14.775000           7.376176   \n",
       "\n",
       "                                               lemm_sentences  sentences_count  \n",
       "Unnamed: 0                                                                      \n",
       "0           [[\"сегодня\", \"беззаботный\", \"детство\", \"суетли...               34  \n",
       "3           [[\"спасибо\", \"большой\", \"ваш\", \"помощь\", \"реги...               17  \n",
       "4           [[\"ох\"], [\"заболеть\"], [\"пускай\"], [\"давно\", \"...               22  \n",
       "10          [[\"двое\", \"спать\"], [\"двое\", \"дым\", \"папироса\"...               35  \n",
       "11          [[\"вспомнить\", \"когда-то\", \"проходить\", \"тест\"...               40  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data = pd.read_excel('./data/clean_data.xlsx', index_col=0)\n",
    "noises_data = pd.read_excel('./data/with_noises.xlsx', index_col=0)\n",
    "clean_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88b7cf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "    'mean_usage_[URL]',\n",
    "    'mean_usage_[ADDRESS]',\n",
    "    'mean_usage_[NUMBER]', 'mean_usage_[QUOTE]',\n",
    "    'mean_usage_[PUNCEM]', 'mean_usage_[REMOVED]', 'mean_usage_,',\n",
    "    'mean_usage_!', 'mean_usage_?', 'mean_usage_:',\n",
    "    'mean_usage_-', 'mean_usage_(', 'mean_usage_)', 'mean_usage_ADJ',\n",
    "    'mean_usage_ADP', 'mean_usage_ADV',\n",
    "    'mean_usage_NOUN', 'mean_usage_DET',\n",
    "    'mean_usage_NUM', 'mean_usage_VERB',\n",
    "    'mean_usage_PART', 'mean_usage_PRON', 'mean_usage_SCONJ',\n",
    "    'mean_usage_sentence_length', 'mean_token_length',\n",
    "    'sentences_count',\n",
    "]\n",
    "target_col = 'Пол'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63ab2c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = NewsEmbedding()\n",
    "test_size=0.2\n",
    "\n",
    "X_train, X_test, y_train, y_test, get_num, get_vect = prepare_input(clean_data, test_size, emb, feature_cols, target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd5f7962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGbCAYAAAAr/4yjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAOL5JREFUeJzt3Xl4U2XCNvA7SdN03zfKVqCsZbUIyiKIICCKiIgo6gwOwuAyo+jLvMyMAm7ohy8jCu4CoqjsMCgCgiiLyF7WUlraQil039OmaZLz/VE5Ulra0iZ5ck7u33Xl0qbNOXdCmzvnec6ikSRJAhEREQCt6ABEROQ6WApERCRjKRARkYylQEREMpYCERHJWApERCRjKRARkYylQEREMpYCERHJWApERCRjKSjA8uXLodFo5JuXlxc6deqEZ599FtnZ2aLjEZGKeIgOQI336quvol27djCZTNi7dy8+/PBDbNmyBadOnYKPj4/oeESkAiwFBRk9ejT69u0LAJg6dSpCQ0OxcOFCbNq0CY888ojgdESkBhw+UrBhw4YBANLS0gAABQUFeOmll9CjRw/4+fkhICAAo0ePxvHjx2s91mQyYe7cuejUqRO8vLzQokULjB8/HufPnwcApKen1xiyuv42dOhQeVk///wzNBoNVq1ahX/+85+IioqCr68vxo4di4yMjFrrPnDgAEaNGoXAwED4+PhgyJAh2LdvX53PcejQoXWuf+7cubV+9quvvkJ8fDy8vb0REhKCSZMm1bn++p7btWw2G959913ExcXBy8sLkZGRmD59OgoLC2v8XExMDO69995a63n22WdrLbOu7AsWLKj1mgJAZWUl5syZg9jYWBgMBrRu3RqzZs1CZWVlna/VtW70ul29paen1/j5Dz74AHFxcTAYDIiOjsYzzzyDoqKiWstt7Gv3zjvvYMCAAQgNDYW3tzfi4+Oxdu3aBnOTeNxSULCrb+ChoaEAgNTUVGzcuBEPPfQQ2rVrh+zsbHz88ccYMmQIzpw5g+joaACA1WrFvffei507d2LSpEn4+9//jtLSUvz44484deoUOnToIK/jkUcewT333FNjvbNnz64zzxtvvAGNRoN//OMfyMnJwbvvvovhw4cjISEB3t7eAICffvoJo0ePRnx8PObMmQOtVotly5Zh2LBh2LNnD/r161drua1atcL8+fMBAGVlZZgxY0ad63755ZcxceJETJ06Fbm5uXj//fdxxx134NixYwgKCqr1mGnTpmHw4MEAgPXr12PDhg01vj99+nQsX74cU6ZMwd/+9jekpaVh8eLFOHbsGPbt2we9Xl/n63AzioqK5Od2LZvNhrFjx2Lv3r2YNm0aunbtipMnT+I///kPzp07h40bNza47Gtft6u2bNmCb775psZ9c+fOxbx58zB8+HDMmDEDSUlJ+PDDD3Ho0KEbPs+GXrtFixZh7NixmDx5MsxmM7799ls89NBD+O677zBmzJgGs5NAErm8ZcuWSQCkHTt2SLm5uVJGRob07bffSqGhoZK3t7d06dIlSZIkyWQySVartcZj09LSJIPBIL366qvyfUuXLpUASAsXLqy1LpvNJj8OgLRgwYJaPxMXFycNGTJE/nrXrl0SAKlly5ZSSUmJfP/q1aslANKiRYvkZXfs2FEaOXKkvB5JkqTy8nKpXbt20ogRI2qta8CAAVL37t3lr3NzcyUA0pw5c+T70tPTJZ1OJ73xxhs1Hnvy5EnJw8Oj1v3JyckSAOmLL76Q75szZ4507Z/Dnj17JADSypUrazx269atte5v27atNGbMmFrZn3nmGen6P7Hrs8+aNUuKiIiQ4uPja7ymX375paTVaqU9e/bUePxHH30kAZD27dtXa33XGjJkiBQXF1fr/gULFkgApLS0NEmSJCknJ0fy9PSU7r777hq/O4sXL5YASEuXLq3x+Ma8dpJU/W96LbPZLHXv3l0aNmxYvblJPA4fKcjw4cMRHh6O1q1bY9KkSfDz88OGDRvQsmVLAIDBYIBWW/1ParVakZ+fDz8/P3Tu3BlHjx6Vl7Nu3TqEhYXhueeeq7WO64cBbsYTTzwBf39/+esJEyagRYsW2LJlCwAgISEBycnJePTRR5Gfn4+8vDzk5eXBaDTirrvuwu7du2Gz2Wos02QywcvLq971rl+/HjabDRMnTpSXmZeXh6ioKHTs2BG7du2q8fNmsxlA9et1I2vWrEFgYCBGjBhRY5nx8fHw8/OrtcyqqqoaP5eXlweTyVRv7szMTLz//vt4+eWX4efnV2v9Xbt2RZcuXWos8+qQ4fXrb6odO3bAbDbj+eefl393AOCpp55CQEAAvv/++xo/35jXDoC8ZQgAhYWFKC4uxuDBg2v8HpJr4vCRgixZsgSdOnWCh4cHIiMj0blz5xp/yDabDYsWLcIHH3yAtLQ0WK1W+XtXh5iA6mGnzp07w8PDvv/8HTt2rPG1RqNBbGysPH6dnJwMAPjTn/50w2UUFxcjODhY/jovL6/Wcq+XnJwMSZJu+HPXD39cHSu//o34+mUWFxcjIiKizu/n5OTU+Hr79u0IDw+vN+f15syZg+joaEyfPr3WeHtycjISExNvuMzr199UFy5cAAB07ty5xv2enp5o3769/P2rGvPaAcB3332H119/HQkJCTXmQJrzoYOcg6WgIP369ZP3PqrLm2++iZdffhlPPvkkXnvtNYSEhECr1eL555+v9QlchKsZFixYgN69e9f5M9e+2ZjNZly5cgUjRoxocLkajQY//PADdDpdvcsEgKysLABAVFRUvcuMiIjAypUr6/z+9W/W/fv3x+uvv17jvsWLF2PTpk11Pj4xMRHLly/HV199VeeYvc1mQ48ePbBw4cI6H9+6desbZnekxrx2e/bswdixY3HHHXfggw8+QIsWLaDX67Fs2TJ8/fXXzopKTcRSUJG1a9fizjvvxOeff17j/qKiIoSFhclfd+jQAQcOHEBVVZVdJkuvurolcJUkSUhJSUHPnj3l9QJAQEAAhg8f3uDyjh8/jqqqqnqL8OpyJUlCu3bt0KlTpwaXe+bMGWg0mlqfjq9f5o4dOzBw4MAaQyE3EhYWVus51TcZPHv2bPTu3RsPP/zwDdd//Phx3HXXXQ79dN22bVsAQFJSEtq3by/fbzabkZaWVus5Nea1W7duHby8vLBt27Yaw0zLli2zc3pyBM4pqIhOp4MkSTXuW7NmDTIzM2vc9+CDDyIvLw+LFy+utYzrH38zVqxYgdLSUvnrtWvX4sqVKxg9ejQAID4+Hh06dMA777yDsrKyWo/Pzc2tlV2n09W5u+e1xo8fD51Oh3nz5tXKL0kS8vPz5a8tFgvWrVuHfv361TsEMnHiRFitVrz22mu1vmexWOrcXbOx9u/fj02bNuGtt9664Rv+xIkTkZmZiU8//bTW9yoqKmA0Gpu8/msNHz4cnp6eeO+992q8dp9//jmKi4tr7CnU2NdOp9NBo9HUGL5MT09v1B5TJB63FFTk3nvvxauvvoopU6ZgwIABOHnyJFauXFnjEyBQPSG8YsUKzJw5EwcPHsTgwYNhNBqxY8cOPP3007j//vubtP6QkBAMGjQIU6ZMQXZ2Nt59913ExsbiqaeeAgBotVp89tlnGD16NOLi4jBlyhS0bNkSmZmZ2LVrFwICArB582YYjUYsWbIE7733Hjp16oSff/5ZXsfVMjlx4gT279+P22+/HR06dMDrr7+O2bNnIz09HePGjYO/vz/S0tKwYcMGTJs2DS+99BJ27NiBl19+GSdOnMDmzZvrfS5DhgzB9OnTMX/+fCQkJODuu++GXq9HcnIy1qxZg0WLFmHChAlNep22b9+OESNG1Lu19Pjjj2P16tX461//il27dmHgwIGwWq04e/YsVq9ejW3btjW4BdUY4eHhmD17NubNm4dRo0Zh7NixSEpKwgcffIBbb70Vjz32GADc1Gs3ZswYLFy4EKNGjcKjjz6KnJwcLFmyBLGxsThx4kSzM5ODidvxiRrr6i6phw4dqvfnTCaT9OKLL0otWrSQvL29pYEDB0r79++XhgwZUmN3R0mq3mXwX//6l9SuXTtJr9dLUVFR0oQJE6Tz589LktS0XVK/+eYbafbs2VJERITk7e0tjRkzRrpw4UKtxx87dkwaP368FBoaKhkMBqlt27bSxIkTpZ07d9ZYd0O3P/3pTzWWu27dOmnQoEGSr6+v5OvrK3Xp0kV65plnpKSkJEmSJOm5556T7rjjDmnr1q21MtW1W6UkSdInn3wixcfHS97e3pK/v7/Uo0cPadasWdLly5fln7nZXVI1Go105MiRGvfX9W9kNpult99+W4qLi5MMBoMUHBwsxcfHS/PmzZOKi4trre/65TVml9SrFi9eLHXp0kXS6/VSZGSkNGPGDKmwsFD+/s2+dp9//rnUsWNHyWAwSF26dJGWLVt2w9eYXItGkpoxXkCE6iOa77zzTqxZs6bJn56vlZ6ejnbt2iEtLQ0xMTF1/szcuXORnp6O5cuXN3t9RPQHzikQEZGMcwrkcvz8/DB58uR6JzN79uwpn7aDiOyHpUAuJywsDF999VW9PzN+/HgnpSFyL5xTICIiGecUiIhIxlIgIiIZS4GIiGQsBSIikrEUiIhIxlIgIiIZS4GIiGQsBSIikrEUiIhIxlIgIiIZS4GIiGQsBSIikrEUiIhIxlIgIiIZS4GIiGQsBSIikrEUiIhIxlIgIiIZS4GIiGQsBSIikrEUiIhIxlIgIiIZS4GIiGQsBSIikrEUiIhIxlIgIiIZS4GIiGQsBSIikrEUiIhIxlIgIiIZS4GIiGQsBSIikrEUiIhIxlIgIiIZS4GIiGQsBSIikrEUiIhIxlIgIiIZS4GIiGQeogMQ2VulxYqckkrklVWirNICY6UFpabq/5ZVWlBWaYWx0oJKixU2CbBJErp5FWKq5VtA6wFodb//9/ebTg/4hAJ+Eb/fIgHfiOr7tPxcRerCUiDFKTSakZJbhrRcIy4XVyC7xISsYhOySiqRXWJCgdF808u0RuYAxd/e3IO0HoBPGOAX/kdRXFscwTFARDfA0+em8xCJwlIgl5VVbMLZrBKk5JThfG4ZzucYkZJb1qQ3fYewWYCyrOobTtb9MxotENIBiOoORPUAIntU/39AtFOjEjUWS4FcQlmlBScyipBwqQgJF4tw/FIRsksqRcdqPskG5CdX305v+ON+n1Ag8veiuHoL6wzo+CdJYvE3kITIKTFhT3IeDqTlIyGjCCk5ZbBJolM5UXk+kPZL9e0qnaG6HDoMA2KHA636Vs9vEDkRS4GcotxswYHUAuxJzsPelFycyy4THcn1WCuBzMPVt93/D/AKAtoPrS6I2OFAQAvRCckNsBTIYVJzy7D1dBZ+ScrFsYtFMFttoiMpi6kIOLOx+gYAEXFA7F3VBdHmdsDDU2A4UiuWAtnVuexSbDl5BT+czEJSdqnoOOqSc7r69ut7gKcfEDO4uiQ6jwYCW4lORyqhkSTJnUZyyQFOXy7GDyez8MOpKzifaxQdp0nuj8zBouLnRcdoGo0WaDcE6PMY0PU+wMMgOhEpGLcUqEkKjWZsOJaJ1YczcDaLWwRCSTYgdVf1zSsI6DGhuiCi+4hORgrEUqBGs9kk7EnJw+rDGfjxTDbMFs4RuBxTEXDos+pbZA+gz2Sgx0TAN1R0MlIIDh9Rg64UV+CbgxlYd+QSMosqRMdxCEUPHzVE5wl0GgX0ebx6DoK7uVI9uKVAN3TkQiGW7kvDtlNZsLjVQQQqYzUDif+tvvm3AHo9AvSfDvhHiU5GLoilQDXYbBK2ns7CJ7tTkZBRJDoO2VvpFWDvQuC3D4BbngAGPg8EthSdilwIS4EAAKYqK9YcuYTP96QiPb9cdBxyNIsJOPgJcGQ50HsyMOgFILit6FTkAlgKbs5sseGbgxexZFcKckpVcK4hujlWM3BkGXDsS6DnJOCOF4GQ9qJTkUAsBTdlsdqw5sglLP4pRbWTx3QTbBYg4Svg+DfVu7QOfgkI7yQ6FQnAUnAzVpuEDccy8d7OZFws4DARXUeyAidWASfXAN3GAXf8DxDZTXQqciKWghvZdjoLb289i1SFHnVMTiTZgNPrq0/33fVeYMSrHFZyEywFN3AuuxTzNp/GvpR80VFIcSQgcTOQ/GP1nkqDXgD0XqJDkQOxFFSsuLwKC39MwlcHLsLK4wyoOSwm4Je3qoeW7nkH6DhcdCJyEJaCClltEr4+cAELfzyHwvIq0XFITQrTgJUPVp94b9TbPMZBhVgKKpOQUYT/XXeCJ6kjx0rcDKT8BAyZBdz+DKDTi05EdqIVHYDsw1RlxRvfn8GDH/7KQiDnqDICO+YAHw0G0veJTkN2wlJQgQOp+Rj17m58uieNcwfkfLmJwPJ7gPXTgLIc0WmomVgKClZWacG/N57EpE9/46kpSLwTq4DFfYGjK0QnoWbgnIJC7U3Owz/WneDRyORaTMXAf58DUn8G7lsEGPxFJ6KbxFJQmCqrDe9sT8Inu1PBK2GQyzq1Drh8DJiwDIjuLToN3QQOHylIRkE5HvpoPz7+hYVAClCQCnw+AvjtI9FJ6CawFBRi8/HLuOe9PbzGASmL1Qxs/QfwzaNARaHoNNQILAUXV2G2Ytba43jum2MoNVlExyFqmqTvq3ddzTgoOgk1gKXgwi7kG3H/kr1YffiS6ChEzVecASwbDexZCI5/ui6Wgovak5yLsYv34Vx2megoRPZjswA75wFfPQiU5YpOQ3VgKbigz/ak4s/LDqG4guctIpU6vxP4aBBwYb/oJHQdloILqbRY8eLq43j9+0QemUzqV5YFrLgfOLlWdBK6Bo9TcBE5JSZM+/II9y4i92KtBNZNBYouAINfFJ2GwC0Fl5CcXYr7l+xjIZCbkoCdr1YfCW3lHnaisRQEO3KhABM+2o8rxSbRUYjEOroC+PohoJJn+RWJpSDQzsRsTP7sACeUia46/xOw7B7umSQQS0GQ1YczMP3LIzBV2URHIXItWSeApSOBoouik7glloIAS3alYNbaE7BwDyOiuhWcBz4fCeQkik7idlgKTjZ/SyIWbEsSHYPI9ZVerj4COuOQ6CRuhaXgRPO3JOLj3amiYxApR0Vh9bEMqT+LTuI2WApO8tYPZ1kIRE1RZaw+yypPpucULAUneHvrWXz0y3nRMYiUq8oIrHwIyD4tOonqsRQcbMG2s/jwZxYCUbOZioAvH6i+eA85DEvBgRZuT8KSXSwEIrspywZWjANKrohOolosBQf5bE8q3vspRXQMIvUpulC9xVBeIDqJKrEUHGD90Ut4Ywv3ryZymNzE6jkGs1F0EtVhKdjZz0k5mLX2BC8sReRomYeBbx8FLGbRSVSFpWBHpzKL8czKozxSmchZUn8G1v0FsFlFJ1ENloKdZBSUY8ryQzCa+ctJ5FSJ/wU2/43XfbYTloIdlJiqMGX5IeSWVoqOQuSejn0F7JgrOoUqsBSayWaT8PdvjiElp0x0FCL3tu9d4Mwm0SkUj6XQTP/3YxJ2JfHc70QuYeMzQB53BW8OlkIzbDl5hQenEbkScymw6jHuqtoMLIUmOptVgpfWHBcdg4iul5sIbH5edArFYik0QXF5FaatOIJy7mlE5JpOrgYOfio6hSKxFG6SzSbhuW+P4WJBuegoRFSfbf8ELh0RnUJxWAo36aPd57H7HCeWiVye1QysfgIw5otOoigshZtwPKMI//nxnOgYRNRYJZeA9VMBm010EsVgKTSSsdKCv397DFVWHjVJpCjnfwJ+ni86hWKwFBrp5U2nkJ7PeQQiRdq9ADi3XXQKRWApNMKmhEysP5opOgYRNZkEbJgOGPNEB3F5LIUGZBSU498bT4mOQUTNVVEAbJ0tOoXLYyk0YNbaEyg1WUTHICJ7OLkaSN4hOoVLYynU49uDF7E/lbuzEanK9y/wNBj1YCncQE6JCW/ykppE6lN0Edj1pugULoulcAOvbDqNEg4bEanTbx8CmUdFp3BJLIU6bD11BVtPZ4mOQUSOIlmrr9Zm5Qe/67EUrlNcUYVXNp0WHYOIHC3rJLD/fdEpXA5L4Tpvbz2LHF5Wk8g9/Pw2UJAqOoVLYSlc4/TlYnx78KLoGETkLJYKXnvhOiyFa7z23RnYeGojIveS9gtwbKXoFC6DpfC7raeu4LfUAtExiEiE7f8Cyvn3D7AUAACVFive3HJWdAwiEqWiEPj1PdEpXAJLAcDSvem8khqRuzvwCVDGC2i5fSnkllZiya4U0TGISLQqI7B3oegUwrl9KSzaeQ5llTyAhYgAHF4KlFwWnUIoty6FzKIKrD50SXQMInIVFlP1BXncmFuXwuKfUmC28tqtRHSNo18ChemiUwjjtqWQUVCOtUcyRMcgIldjq6o+0tlNuW0pLNmVgiorj1QjojqcWAXkJYtOIYRblkJGQTnWHeVcAhHdgGR122suuGUpLP6JWwlE1IDTG4As97s+u9uVwpXiCm4lEFEjSMCuN0SHcDq3K4Xlv6bDwrPeEVFjJG0BrpwQncKp3KoUys0WfHuQexwR0U049JnoBE7lVqWw7sglFFdUiY5BREpyah1gKhGdwmncphQkScKyfemiYxCR0pjLqndRdRNuUwq7knKQmmcUHYOIlOjIctEJnMZtSuHzvWmiIxCRUmWfAi4eEJ3CKdyiFFJyyrAvJV90DCJSssNLRSdwCrcohTU8xxERNdeZjW5xyU7Vl4LVJmHD0UzRMYhI6SwmIOFr0SkcTvWl8Mu5HOSUVoqOQURqcGSZ6AQOp/pSWHOYp7QgIjvJTwFSfxGdwqFUXQqFRjN2JuaIjkFEaqLyCWdVl8LGhExeWY2I7Ovs90CZej9sqroUeDZUIrI7WxWQuFl0CodRbSmk5xlxKtN9zldCRE6U9IPoBA6j2lLYcuqK6AhEpFZpuwGzOk+bo9pS+OFklugIRKRW1krg/E+iUziEKkvhUmE5TmYWi45BRGqm0iEkVZbCj2eyRUcgIrU7tw2wqW/vRpYCEVFTlOcBlw6KTmF3qiuF4vIqHExT/0mriMgFqHAISXWlsDclDxabJDoGEbkDloLr23c+T3QEInIXeUlA/nnRKexKdaXwawpLgYicSGVbC6oqhcyiCqTnl4uOQUTuhKXguvYlcyuBiJws4zegokh0CrtRVylwPoGInM1mATIPi05hN6oqhV/P54uOQETuKPOY6AR2o5pSSMkpRS4vu0lEIlw+KjqB3aimFI5dLBIdgYjcVSZLweWcuMQT4BGRIGVZQMll0SnsQj2lwLOiEpFIKtlaUEUpVFltSLzCq6wRkUCX1THZrIpSOHulFGaL+k5hS0QKopLJZlWUwvFLRaIjEJG745aC6zjBUiAi0SoKgYJU0SmaTRWlkHilVHQEIiJVTDarohTS8oyiIxARqWIISfGlkF1iQlmlRXQMIiKWgis4n1smOgIRUbWcRLstasmSJYiJiYGXlxf69++Pgwedcz1oxZdCai6HjojIRVQUAJXN/6C6atUqzJw5E3PmzMHRo0fRq1cvjBw5Ejk5OXYIWT+WAhGRPRVdaPYiFi5ciKeeegpTpkxBt27d8NFHH8HHxwdLly61Q8D6Kb8U8jh8REQupLB5pWA2m3HkyBEMHz5cvk+r1WL48OHYv39/c9M1SPGlwD2PiMilFF1s1sPz8vJgtVoRGRlZ4/7IyEhkZWU1a9mNofhSuFJkEh2BiOgPdhg+EknRpVBoNMNs5TmPiMiFNHP4KCwsDDqdDtnZ2TXuz87ORlRUVLOW3RiKLoXsUm4lEJGLKb3SrId7enoiPj4eO3fulO+z2WzYuXMnbr/99uama5CiSyGnhJffJHKGt/ZWQjOvBM9vrflBbH+GBcO+MML3zRIEzC/BHcuMqKiSmrXMmdtMCHm7BK3/U4qVJ6pqfG/N6Src9015856Mo5VlN/wzDZg5cyY+/fRTfPHFF0hMTMSMGTNgNBoxZcoUOwSsn4fD1+BAObwmM5HDHcq04uMjZvSMrPkZcn+GBaNWlmP2IAPeH+0FDy1wPNsGrabpy9ycVIWvT1Zh++O+SM634cn/VmBkrA5hPloUmyT866dK7HjCx55Pz/7KcgBJAjSNeCFu4OGHH0Zubi5eeeUVZGVloXfv3ti6dWutyWdHUPaWAoePiByqzCxh8voKfHqfN4K9ar7JvbCtEn/r54n/HWRAXIQOncN0mBinh8Gj/jfD+paZmGfD0Bgd+kbr8EgPPQIMGqQVVm95zPrRhBl99WgT6OJvW7YqoDy/2Yt59tlnceHCBVRWVuLAgQPo37+/HcI1zMVf3fpx+IjIsZ7ZYsKYjh4Y3r7moEKO0YYDmVZE+Gox4HMjIt8pxZDlRuy92PB5yG60TADoFanD4ctWFFZIOHLZiooqCbEhWuy9aMHRLCv+1t/Tbs/NoUodv+uooyi6FHLLWApEjvLtqSocvWLF/OGGWt9LLaze62/uL5V46hY9tk72wS1ROty1ohzJ+dYmLRMARsZ64LGeetz6aRn+vKkCX4zzhq8nMON7Ez4a440PD1eh8+IyDFxqxOmcG69HODvMK4ii6DmFMhPPjkrkCBnFNvx9qwk/Pu4DrzqGg2y/zyVPj9djSp/qT+99WuiwM82CpceqMH+47qaXedXcoV6YO9RL/nrez5UY3s4Deh3w+u5KnJzhi+/OWfDExgocmebXzGfqIMZc0QmaTNGlUG5mKRA5wpErVuQYJdzy8R9nDLBKwO4LViw+aEbSs9Vvxt3Caw42dA3X4mJJ3ccONbTMyn/7Q3fdLPXZPCu+OlmFY9N9sfSYGXe01SHcV4uJcXo8+V8TSisl+BuaPqHrMBbljmIouhSMlS68+UikYHe188DJGb417puyqQJdwnT4x0BPtA/WINpfg6S8mgVwLt+G0bF1v600tMzrC0GSJEz/zoSFdxvg56mB1QZU/b66q/+1Nm7vV+ezVTX8My5K0aXALQUix/A3aNA9ouYQkK9eg1DvP+7/nwGemPNzJXpF6dA7SocvEsw4m2fD2of+mAy+a4URD3TR49l+no1a5rU+O1qFcB8N7uusBwAMbOOBub9U4rdLFvyQbEG3cC2CvFxwKwEArMp9b1J0KRjN3FIgEuX52wwwWYAXtplQUCGhV6QOPz7ugw4hfwwpnS+wIa/85k9Fk11mwxt7KvHrX/7YsujXUocXbzdgzNcViPDV4Itx3nZ5Hg6h4C0FjSRJrroB1qC4V7ayGMgu7o/MwaLi50XHILW4aw4weKboFE2i6F1SK6pYCETkgmzKHT5SbCmYLTZ5tzgiIpdiVe7wkWJLoRmnFSEiciwFzykotxREByAiuhFuKTiflpsKZEeZJhfek4WUh3MKzqdtzPl5iRrpcLE/rL4RomOQWnBLgUj5cgN7iY5AasE5BTG4sUD2dErXRXQEUgsFH9Gs8FJgK5D97CiLER2B1EKn3JNFKDc5AIOHFhYXPaK5aO9KFO/7psZ9HiGt0PKpjwAA+VsXw3QhAdayAmj0XjC07IrgoX+GPrR1vcutystA4S/LYLp4CpCs0Ie2QfgDs+ERUD0eXrDzUxhP7YRG74WgIX+CX9yd8mONZ/fCeGonIibMsfOzVYfNOZGY72WAxqrcM1ySi/AOEZ2gyRRdCv5eepc+zYU+rA0iH37jjzu0f2yYeUbFwjduKDwCwmGtKEXxvq+RveoVtPzrZ9Boa58cDACqCq8ga+Us+PUcgaBBk6Hx9EFV3kVodNUnICtPOQBj4i+ImPgaLIWXkf/DIni3uwU6n0DYKo0o2r0CkZNed+hzVjKjVQtjaHf45RwRHYWUzjtYdIImU/Twkb+Xi3eaVgedX/AfN59A+Vv+vUfBq3V3eARGwhAVi6DBj8NamgtLcc4NF1e0ewW8O/RF8J1PwjOyA/TBLeDTsT90vkEAgKr8DHi17gFDi47w7TYEGk8fWIqrrwBVuGsZ/PvcI29RUN3OG7qJjkBqoOBScPF31fq5eilYCi/j0pInoNHp4dmyC4KH/KnON2Wb2YSykzvgERgJj4CwOpclSTZUpB5GQL/xyF71Msw5qfAIjETgbQ/Bp9PtAADP8HYoS9gGq6kMlqIsSJZKeARHw3TpNMzZ5xFy9wyHPl812GeOBfdBombz4fCREP5eetERbsjQojNC73kB+pCWsJYVoHjfN8ha+Q9EP7kEWoMPAKD06Pco/HkZpCoTPEJaIeLh16HR1f2cbMZiSOYKlBxYi6DBjyN46BRUpB1B7oY3EfnIm/Bq0wPe7ePhGzcUWV+8AI2HJ8LGvACt3oCCbR8gdMwLKD22BaVHv4POOwAhI5+FZ3hbZ74kirAxrxWeFh2ClI9bCmK48paCd4e+f3wR0Q6G6M649OGTMJ7dC/9edwMAfOOGwiumN6zGQpQcXI+8TW8h6rEF0Hh41lqeJFWfk9479jYE3DoOAOAZ2R6VmYkoTfgBXm16AACCBk1G0KDJ8uOK9n4Nr5je0Gh1KN6/CtFPLkFFykHkf78QLf68yEHPXrnOGb1RFRkDfXG66CikZAouBYXPKbjulsL1tF5+0Ie0hKXo8h/3GXyhD2kJr9bdET5uNqoKLqH83P46H6/zCQC0OujDau6dpA9tDWtJ3RcJr8rPgPHMLgQNfgymiyfh1ao7dD6B8OkyGObs87BVltvvCarIZf+eoiOQ0il47yNFl0KAt+tuKVzPZq6ApegKdL43+GWRqm/SDQ6P1+j0MER1hKUgs8b9VQWZ0NUxTyFJEvK3LUHwsKnQenoDkg3S1fOxXP2vdPNXxHIHx6ROoiOQ0nFLoWG7d+/Gfffdh+joaGg0GmzcuLHZywzzNTQ/mIMU/vQ5TBdPwlKcDdOlROSufwPQaOHbbQiqirJQvH81KrNSYCnJqf7+pvnQeHjCu/0fw06Zn/4V5ed+lb8O6D8exsQ9KE3YiqrCyyg5shkVKQfhf8s9tdZfdnwbdN4B8IntDwAwtOwK04UTqMw8i5JDm6APbQOtl5/jXwgF2lbSRnQEUjIPb0DvJTpFkznto7bRaESvXr3w5JNPYvz48XZZZmSg677wltI85G1eAGtFCXTegTC06oaox/8POp9ASFYLTJdOo+Twf2EzlUHnGwRD6zhEPbZA3r0UACwFl2oM8fh0GoDQkU+j+Lc1KNz5CTxCWiL8gX/Cq1VcjXVbjYUo3r8aUY8tkO8zRHdGQL8HkLN2HrQ+gQgb84LDXwOl2p4XAinAH5rKUtFRSIkUvOcRIOgazRqNBhs2bMC4ceOatZwDqfl4+JPf7BOK6BrHYpYgOGuf6BikRJHdgRnK/d1R9JxClAtvKZCyndXHNfxDRHVR8HwCoIJS4DnxyBF+qWgnOgIplW/dB6AqhaJLweChQ7if6042k3Ktz42GpFH0nweJEtpRdIJmUfxvfctgXkaR7C+nUo/K4M6iY5AShSv790bxpdA62Ed0BFKpC77dRUcgJQpX9sWanLZLallZGVJSUuSv09LSkJCQgJCQELRp0/T9wjuEc197cozD1o5Q9mc+cjqNDgjj8FGjHD58GH369EGfPn0AADNnzkSfPn3wyiuvNGu5nSJZCuQYmwvqv+ARUS3BMYCHsuc5nbalMHToUDjikIiOLAVykN+KAmELCYe2vO5zSxHVovChI0AFcwoxob7Q67hfKjlGTlBv0RFISRQ+yQyooBQ8dFq0C/MVHYNU6pRW+X/k5ETcUnANHSP8RUcgldppjBEdgZSEWwqugfMK5Cj/zY2EpFP2xCE5iUbLUnAVXVsEiI5AKmW06GAM4XmQqBECWwN65R9Mq4pS6NMmSHQEUrHz3iwFagQVzCcAKimFCH8vtAxSfkOTa9pXGSs6AilBBEvBpXBrgRxlY14r0RFICdoMEJ3ALlRTCre0UfY5zMl1nTN6oyqgregY5Mq0HkDMQNEp7EI1pcAtBXKkKwE9RUcgV9aiN2BQx67xqimFuOhAeHqo5umQizkmdRIdgVxZuztEJ7Ab1byLenpo0T2au6aSY2wt4fAR1YOl4JoGdFD2ZfDIdW3PC4GkkuEBsjOdAWhzm+gUdqOqUrijU7joCKRSVkmLomDOK1AdWt2qioPWrlJVKdzSJgj+BqedDZzczFl9N9ERyBW1HyI6gV2pqhQ8dFrc1iFUdAxSqd2mdqIjkCtS0XwCoLJSADiERI6zIScakkZ1fzLUHJ5+QMt40SnsSnW/4UM6shTIMbIqPVEZzF1T6RptbgN0etEp7Ep1pdAm1AcxoT6iY5BKXfTtIToCuRKVDR0BKiwFABjaOUJ0BFKpQ9aOoiOQK2k/VHQCu1NlKYzp2UJ0BFKpzQWtRUcgVxHSHmjRS3QKu1NlKfRtG4zIAF4ti+zvt6JA2Hw4b0UAekwUncAhVFkKGo0Go7tza4EcIzdIfZ8OqQl6shQUhUNI5CindOq4mAo1Q8u+QGgH0SkcQrWlwCEkcpSdZTGiI5BoKt1KAFRcChxCIkfZlBsJSccPHG5L6wF0f1B0CodRbSkAwH29WApkf0aLDsaQONExSJQOwwBf9Z6RWdWlEN82BO3DfUXHIBU678VScFs9HxadwKFUXQoA8HBf7ldO9rffrM5JRmqApx/Q+R7RKRxK9aXwYHwr6HUa0TFIZTbmtxIdgUToci/gqe7T6Ki+FML8DBjeNVJ0DFKZs2U+sAS0ER2DnE3Fex1dpfpSAIBJ/fjHS/Z3OYAHsbkVv0hVnuvoem5RCoNjw9AySD2XyyPXcEziabTdSq9JgFYnOoXDuUUpaLUaTOSEM9nZ1pK2oiOQs+g8gf4zRKdwCrcoBQB4tH8beHq4zdMlJ9ieFwLJ0090DHKGng8DAe5x3JPbvEuG+xswvk9L0TFIRaySFkUhnFdQPY0WGPh30Smcxm1KAQCmDm4PDfdOJTtK0ncVHYEcrfM9QJj7XFzJrUohNsIPd3XhVdnIfnZXtBcdgRxt0AuiEziVW5UCADw1mH/EZD/rc6Mhadzuz8h9tB0ItOorOoVTud1vc//2oejVOkh0DFKJrEpPVAZz11TVGvi86ARO53alAADTuLVAdnTRt4foCOQIEXFAp7tFp3A6tyyF0d2j0CmSuxKSfRy2xIqOQI7gRnscXcstS0Gr1WDmCG7yk318V8TTqKhOYBtVX0inPm5ZCgAwqnsL9GwVKDoGqcCvhYGw+aj3oitu6fanAZ2H6BRCuG0pAMCLd3cWHYFUIjeot+gIZC++4cAtT4hOIYxbl8KQTuHoFxMiOgapwCldF9ERyF6GvQx4uu8VG926FADgpZHcWqDm21kWIzoC2UOLXkCfx0WnEMrtS6FfuxAM6RQuOgYp3KbcSEg6T9ExqLlGvQ1o3ftt0b2f/e/+eU9X6LQ8KRI1ndGigzEkTnQMao7uE4C2t4tOIRxLAUDnKH88yquzUTOlerEUFEvvA4x4VXQKl8BS+N3MEZ0Q6K0XHYMUbL+ZB7Ep1qAXgECeWh9gKciCfT15QBs1y4b8VqIjUFMEtgEG/E10CpfBUrjGY7e1RbcWAaJjkEKdLfOBJYDDkIpz92uA3kt0CpfBUriGTqvBa+PieCEearLLAT1FR6CbETMYiBsnOoVLYSlcJ75tCB6K5zAANU0COASpGBodMOot0SlcDkuhDv8a0w2RAQbRMUiBthXHiI5AjRX/ZyCqu+gULoelUIdAbz3efIDnyKebtz0/FJInT8vu8vwigWH/Fp3CJbEUbuCurpF4oA93UaObU2XToCikl+gY1JCx7wM+PO9ZXVgK9ZhzXzeE+3MYiW5Okr6r6AhUn1ueADqNFJ3CZbEU6hHk44nXx3HMkW7O7gpe7tVlBbUFRs4XncKlsRQaMDIuCvf1ihYdgxRkQ140JA3/tFyORgs88BFg4JxPffib2wiv3R+H6EAe3EKNc8XkicrgjqJj0PVufwZoO0B0CpfHUmiEIB9PvPdIH3jwTKrUSBm+3HvNpbToDQx7RXQKRWApNFLfmBC8wHMjUSMdsnJLwWV4+gMTlgIevN5FY7AUbsLTQztgcEdeoJ0a9l0hz4HkMu79DxDaQXQKxWAp3ASNRoP/PNybu6lSg34tDITNhx8ghOs9Gej5kOgUisJSuElhfga8+3BvcHqBGpIbxIPYhArrBNyzQHQKxWEpNMHA2DA8P5zzC1S/07ouoiO4L09/4KHlgKev6CSKw1JooueGxWJMjxaiY5AL+6ksRnQE96TRAQ8tAyJ5edSmYCk0kUajwTsP9UJcNC/KQ3XblBsJScc9Xpzunv8HdBwhOoVisRSawdtTh0+f6MuJZ6pTqcUDxhB+WnWq254Bbp0qOoWisRSaKTrIGx8/Hg9PD76UVFuqF0vBabrcC9z9uugUisd3Mju4pU0w5vP6C1SH/eZY0RHcQ3QfYPyngJZvac3FV9BOHoxvhWfv5BsA1bQxn5d2dbjA1sAjqwBPH9FJVIGlYEcvjeyMR/rxSFb6Q2KZDywBrUXHUC9DAPDoasA/UnQS1WAp2Nkb47pjdPco0THIhVwJ6Ck6gjppPaqPRYjsJjqJqrAU7Eyr1eDdSb0xoEOo6CjkIhLAg9gcYsz/AbF3iU6hOiwFBzB46PDJE33Ro2Wg6CjkArYWtxUdQX0GzQTi/yw6hSqxFBzEz+CB5VNuRftwHmbv7rbnh0Ly5NW+7Gbwi8DwOaJTqBZLwYFC/Qz4euptaBfGYnBnVTYNikM4r2AXd/4LuIsXy3EkloKDRQV6YdW029CBWwxuLUnPydBmGz4PGDJLdArVYyk4QUSAF76ddjs6RXIIwV3tNrUXHUHZRr0NDHpedAq3wFJwknB/A7556jZ0ifIXHYUEWJ8bDQm8CMfN01RfOe22v4oO4jZYCk4U6lddDDyzqvu5YvKEOYTX4LgpGi1w/xKg75Oik7gVloKTBft64uupt6FPmyDRUcjJLvry/FiNpvWoPpdRn8mik7gdloIAgT56fPPUbRjRjYfmu5ND1o6iIyiDVg9MWAb0mCA6iVtiKQjipdfh48fi8fhtPLDJXXxfyHMgNUhnAB7+Cug2VnQSt8VSEEir1eC1cd3xj1FdoOEcpOrtKwyCzTtMdAzX5RcF/Pk7oPMo0UncGkvBBcwY2gHvPtwbnjr+c6hdXjAPYqtTy77AtJ+B1v1EJ3F7fBdyEff3bonlT96KIB+96CjkQKd0XUVHcD19HgOmbAECWohOQmApuJQBHcKw+dlB6NqCu6yq1U9lMaIjuA6tBzB6QfVupx68zrmr0EiSJIkOQTVVmK343/UnsCnhsugoZGf+HhacMEyFxmoWHUUsnzBg4hdAzCDRSeg63FJwQd6eOiya1Acv39sNHlrOQKtJqcUD5SFufh6kqJ7V8wcsBJfEUnBhfxnUDl9N7Y8wP0/RUciOUr3iREcQp/sE4C/bgSDunuuqWAou7rb2odj83CDEtw0WHYXsZH9VrOgIzqfRASNeBSZ8Dui9RaehenBOQSGsNgmLdiZjya4UWG38J1Oyrn7l+MEyVXQM5/GPBsYtAToME52EGoGloDAHUvPxwqoEXC42iY5CzZAS8Q94lGSIjuF4vScDI98EvINEJ6FG4vCRwvRvH4ofnr8D9/eOFh2FmuFKgMoPYvOPBh5dA4z7gIWgMCwFBQr01mPRpD54/5E+CPTmwW5KlCB1Fh3BcXpPBp7eD3S6W3QSagKWgoLd1ysaP868A2N68khQpdlWosITIXLrQBU4p6ASOxOz8fLGU5xrUAi9VsI5v2nQmI2io9gH5w5Ug6WgIsZKCxZsS8KK/engDkquLyHmfQRl7Rcdo3n8WwD3LQI6jRSdhOyEw0cq4mvwwNyxcdjw9ECeP0kBkvRKPohN8/vcwW8sBJVhKahQr9ZB2PzsQMy9rxuCedZVl7Xb1F50hKaJGQw8tZNzByrF4SOVK66owvs7k7Fi/wWYrTbRcegaLbzM+BVToIFC/gQj4oDhc7lXkcqxFNxEep4R839IxLbT2aKj0DWSWsyDoTBJdIz6BbQC7vwn0OsRQMvBBbVjKbiZA6n5eP37RJzMLBYdhQDs6LgOsRnrRMeom1cgMGgm0P+vgN5LdBpyEpaCG5IkCdvPZOO9nck4fblEdBy39lb7k5h0eb7oGDXpDEC/p4DBLwI+IaLTkJOxFNzcjjPZWLQzmVsOggwOKcKX5U+LjlFNowV6TASG/QsIaiM6DQnCUiAAwE9ns7FoRzKOX2I5OFtq8N+grcgTF0BnAHpMAG5/BohU8m6yZA8sBarhl3O5+GxPKvYkC3yTcjMH23+GiMs/OX/F/tHArU8C8VMA3zDnr59cEkuB6pSSU4pl+9Kx4Vgmys1W0XFUbVnHvbgz4wPnrbBVP6D/dKDbOEDn4bz1kiKwFKhexRVVWHXoIlbsv4BLhRWi46jS49GZeK3gfxy7Ep0nEDe+ugxa3uLYdZGisRSoUaw2CTsSs7HqUAZ2n8uFhSdXsht/DwtOeP4FGluV/RfuFwn0fbL65hdh/+WT6rAU6KblllZiU0Im1h65hLNZpaLjqMLpVm/DN++4fRam9QBiBlWfmyjuAUDHU51Q47EUqFlOXy7GuiOZ+O/xTOSVmUXHUazNHb9Hj4yVTV+AzhNoNwTodj/QZQyPL6AmYymQXVisNvx6Ph/bz2Rhx5kcZJXwug43458xSZiWNe/mHuThBXS4C+g2Fug8uvoIZKJmYimQ3UmShOOXivHjmSxsP52N5Jwy0ZFcXle/cvxgmdrwD+p9gY4jqoug40jA4Of4cORWWArkcGl5RuxMzMbelDwcSiuAkbu41iklfBY8Si/V/oZPGNDhTqDr2OpC0Hs7Pxy5DZYCOZXFasOJzGLsP5+P/efzcfhCAUxVPKU3AOyNXYlWl76vPqis7QAgZiDQdiAQ3ll0NHIjLAUSymyx4djFQhy+UIjjGUU4canYreYjdFoNOkf6o3ebIDwWW4luLUOBkHaiY5EbYymQy8kuMeFUZjFOXy7BmcslOH2lGJmFFYq/7nSQjx6dIv3ROdIfnaP80SXKH92iA+DjyaOKyXWwFEgRTFVWXCwoR1qeEel5RqT9fkvPNyK7pFJ0PJm/wQMtg70RHeSN6CAvxIT6onNUdRFEBPCaBOT6WAqkeKYqK3JLK5FbVonc0krk/f7fq/9fVF6FiiorKsxWVFRZYfr9/00WG6zXbX5oNIBOo4FO+8ctwEuPAG89Arw8EOitr3EL8vVEdKCXXAQBXjxQjJSNpUBurdJihSRVj+17aDXQaDSiIxEJxVIgIiIZr8JNREQylgIREclYCkREJGMpEBGRjKVAREQylgIREclYCkREJGMpEBGRjKVAREQylgIREclYCkREJGMpEBGRjKVAREQylgIREclYCkREJGMpEBGRjKVAREQylgIREclYCkREJGMpEBGRjKVAREQylgIREclYCkREJGMpEBGRjKVAREQylgIREclYCkREJGMpEBGRjKVAREQylgIREclYCkREJGMpEBGRjKVAREQylgIREclYCkREJGMpEBGRjKVAREQylgIREclYCkREJGMpEBGRjKVAREQylgIREclYCkREJGMpEBGRjKVARESy/w8/RlDxtWd4lAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts = y_train.value_counts()\n",
    "plt.pie(counts, labels=counts.index, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Распределение пола')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd53cfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridSearchRanges:\n",
    "    selector_k = list(range(3, min(10, len(feature_cols)) + 1))\n",
    "    svc_c = [0.01, 0.1, 1 ]\n",
    "    svc_gamma = [ 0.1, 0.5, 1 ]\n",
    "    logistic_c = [0.01, 0.1, 1 ]\n",
    "    gb_criterion = [ 'friedman_mse', 'squared_error']\n",
    "    tree_max_depth = [ 5, 6 ]\n",
    "    tree_max_features = ['sqrt', 'log2', 6, 7]\n",
    "    tree_n_estimators = [100, 150, 200 ]\n",
    "    rf_criterion = ['gini', 'entropy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "287c6ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_model_accuracy = create_accuracy('selector__k', 5, 0.005)\n",
    "all_model_accuracy = create_accuracy('features__num__selector__k', 5, 0.005)\n",
    "separated_models_accuracy = create_accuracy('num_model__selector__k', 5, 0.005)\n",
    "\n",
    "pipeline_grids = [\n",
    "    (\n",
    "        'LogisticRegression vect',\n",
    "        PipelineBuilder(lambda : LogisticRegression(random_state=42, class_weight='balanced'), get_vect).build(), \n",
    "        {\n",
    "            'model__C': GridSearchRanges.logistic_c,\n",
    "        },\n",
    "        'accuracy'\n",
    "    ),\n",
    "    (\n",
    "        'LogisticRegression features',\n",
    "        PipelineBuilder(lambda : LogisticRegression(random_state=42, class_weight='balanced'), get_num).use_std().use_kbest().build(), \n",
    "        {\n",
    "            'selector__k': GridSearchRanges.selector_k,\n",
    "            'model__C': GridSearchRanges.logistic_c,\n",
    "        },\n",
    "        num_model_accuracy\n",
    "    ),\n",
    "    (\n",
    "        'SVC poly features',\n",
    "        PipelineBuilder(lambda : SVC(kernel='poly', random_state=42, class_weight='balanced'), get_num).use_std().use_kbest().build(), \n",
    "        {\n",
    "            'selector__k': GridSearchRanges.selector_k,\n",
    "            'model__C': GridSearchRanges.svc_c,\n",
    "            'model__degree': [2, 3 ]\n",
    "        },\n",
    "        num_model_accuracy\n",
    "    ),\n",
    "    (\n",
    "        'SVC rbf features',\n",
    "        PipelineBuilder(lambda : SVC(kernel='rbf', random_state=42, class_weight='balanced'), get_num).use_std().use_kbest().build(), \n",
    "        {\n",
    "            'selector__k': GridSearchRanges.selector_k,\n",
    "            'model__C': GridSearchRanges.svc_c,\n",
    "            'model__gamma': GridSearchRanges.svc_gamma, \n",
    "        },\n",
    "        num_model_accuracy\n",
    "    ),\n",
    "    (\n",
    "        'Naive bayes features',\n",
    "        PipelineBuilder(lambda : GaussianNB(), get_num).use_std().use_kbest().build(), \n",
    "        {\n",
    "            'selector__k': GridSearchRanges.selector_k,\n",
    "            'model__var_smoothing': [ 1e-8, 1e-7 ]\n",
    "        },\n",
    "        num_model_accuracy\n",
    "    ),\n",
    "    (\n",
    "        'SVC rbf features & vect',\n",
    "        PipelineBuilder(lambda : SVC(kernel='rbf', random_state=42, class_weight='balanced'), get_num).use_std().use_kbest().use_vect(get_vect).build(), \n",
    "        {\n",
    "            'features__num__selector__k': GridSearchRanges.selector_k,\n",
    "            'model__C': GridSearchRanges.svc_c,\n",
    "            'model__gamma': GridSearchRanges.svc_gamma, \n",
    "        },\n",
    "        all_model_accuracy\n",
    "    ),\n",
    "    (\n",
    "        'LogisticRegression features & vect',\n",
    "        PipelineBuilder(lambda : LogisticRegression(random_state=42, class_weight='balanced'), get_num).use_std().use_kbest().use_vect(get_vect).build(), \n",
    "        {\n",
    "            'features__num__selector__k': GridSearchRanges.selector_k,\n",
    "            'model__C': GridSearchRanges.logistic_c,\n",
    "        },\n",
    "        all_model_accuracy\n",
    "    ),\n",
    "    (\n",
    "        'Naive bayes features & vect',\n",
    "        PipelineBuilder(lambda : GaussianNB(), get_num).use_std().use_kbest().use_vect(get_vect).build(), \n",
    "        {\n",
    "            'features__num__selector__k': GridSearchRanges.selector_k,\n",
    "            'model__var_smoothing': [ 1e-8, 1e-7 ]\n",
    "        },\n",
    "        all_model_accuracy\n",
    "    ),\n",
    "    (\n",
    "        'SVC rbf features + Logistic vect = Voting',\n",
    "        (PipelineBuilder(lambda: SVC(kernel='rbf', random_state=42, probability=True), get_num).use_std().use_kbest()\n",
    "            .use_vect(get_vect, lambda: LogisticRegression(random_state=42, class_weight='balanced'), (VotingClassifier, { 'voting': 'soft' }))\n",
    "            .build()\n",
    "        ),\n",
    "        {\n",
    "            'num_model__selector__k': GridSearchRanges.selector_k,\n",
    "            'num_model__model__C': GridSearchRanges.svc_c,\n",
    "            'num_model__model__gamma': GridSearchRanges.svc_gamma, \n",
    "            'vect_model__model__C': GridSearchRanges.logistic_c,\n",
    "        },\n",
    "        separated_models_accuracy\n",
    "    ),\n",
    "    (\n",
    "        'SVC rbf features + Logistic vect = Stacking',\n",
    "        (PipelineBuilder(lambda: SVC(kernel='rbf', random_state=42, probability=True), get_num).use_std().use_kbest()\n",
    "            .use_vect(get_vect, lambda: LogisticRegression(random_state=42, class_weight='balanced'), (StackingClassifier, { }))\n",
    "            .build()\n",
    "        ),\n",
    "        {\n",
    "            'num_model__selector__k': GridSearchRanges.selector_k,\n",
    "            # 'num_model__model__C': GridSearchRanges.svc_c,\n",
    "            # 'num_model__model__gamma': GridSearchRanges.svc_gamma, \n",
    "            # 'vect_model__model__C': GridSearchRanges.logistic_c,\n",
    "        },\n",
    "        separated_models_accuracy\n",
    "    ),\n",
    "    (\n",
    "        'SVC rbf features + SVC rbf = Voting',\n",
    "        (PipelineBuilder(lambda: SVC(kernel='rbf', random_state=42, probability=True), get_num).use_std().use_kbest()\n",
    "            .use_vect(get_vect, lambda: SVC(kernel='rbf', random_state=42, probability=True), (VotingClassifier, { 'voting': 'soft' }))\n",
    "            .build()\n",
    "        ),\n",
    "        {\n",
    "            'num_model__selector__k': GridSearchRanges.selector_k,\n",
    "            # 'num_model__model__C': GridSearchRanges.svc_c,\n",
    "            # 'num_model__model__gamma': GridSearchRanges.svc_gamma, \n",
    "            # 'vect_model__model__C': GridSearchRanges.svc_c,\n",
    "            # 'vect_model__model__gamma': GridSearchRanges.svc_gamma,\n",
    "        },\n",
    "        separated_models_accuracy\n",
    "    ),\n",
    "    (\n",
    "        'SVC rbf features + SVC rbf = Stacking',\n",
    "        (PipelineBuilder(lambda: SVC(kernel='rbf', random_state=42, probability=True), get_num).use_std().use_kbest()\n",
    "            .use_vect(get_vect, lambda: SVC(kernel='rbf', random_state=42, probability=True), (StackingClassifier, { }))\n",
    "            .build()\n",
    "        ),\n",
    "        {\n",
    "            'num_model__selector__k': GridSearchRanges.selector_k,\n",
    "            # 'num_model__model__C': GridSearchRanges.svc_c,\n",
    "            # 'num_model__model__gamma': GridSearchRanges.svc_gamma, \n",
    "            # 'vect_model__model__C': GridSearchRanges.svc_c,\n",
    "            # 'vect_model__model__gamma': GridSearchRanges.svc_gamma\n",
    "        },\n",
    "        separated_models_accuracy\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfa0d6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 12\n",
      "2 / 12\n",
      "3 / 12\n",
      "4 / 12\n",
      "5 / 12\n",
      "6 / 12\n",
      "7 / 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skuld/repositories/nlp/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/skuld/repositories/nlp/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/skuld/repositories/nlp/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/skuld/repositories/nlp/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/skuld/repositories/nlp/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/skuld/repositories/nlp/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/skuld/repositories/nlp/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/skuld/repositories/nlp/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/skuld/repositories/nlp/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/skuld/repositories/nlp/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 / 12\n",
      "9 / 12\n",
      "10 / 12\n",
      "11 / 12\n",
      "12 / 12\n"
     ]
    }
   ],
   "source": [
    "best_models = get_best_models(pipeline_grids, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "43fbdf7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------LogisticRegression vect--------------\n",
      "model parameters: {'model__C': 1}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.64      0.62       811\n",
      "           1       0.68      0.65      0.66       969\n",
      "\n",
      "    accuracy                           0.64      1780\n",
      "   macro avg       0.64      0.64      0.64      1780\n",
      "weighted avg       0.65      0.64      0.64      1780\n",
      "\n",
      "[[519 292]\n",
      " [341 628]]\n",
      "AUC = 0.6440207467242852\n",
      "--------------LogisticRegression features--------------\n",
      "model parameters: {'model__C': 0.1, 'selector__k': 4}\n",
      "selected features: ['x0' 'x4' 'x7' 'x12']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.91      0.79       811\n",
      "           1       0.90      0.67      0.77       969\n",
      "\n",
      "    accuracy                           0.78      1780\n",
      "   macro avg       0.80      0.79      0.78      1780\n",
      "weighted avg       0.81      0.78      0.78      1780\n",
      "\n",
      "[[742  69]\n",
      " [322 647]]\n",
      "AUC = 0.7913092552226291\n",
      "--------------SVC poly features--------------\n",
      "model parameters: {'model__C': 0.01, 'model__degree': 3, 'selector__k': 3}\n",
      "selected features: ['x0' 'x4' 'x7']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.91      0.79       811\n",
      "           1       0.90      0.67      0.77       969\n",
      "\n",
      "    accuracy                           0.78      1780\n",
      "   macro avg       0.80      0.79      0.78      1780\n",
      "weighted avg       0.81      0.78      0.78      1780\n",
      "\n",
      "[[742  69]\n",
      " [322 647]]\n",
      "AUC = 0.7913092552226291\n",
      "--------------SVC rbf features--------------\n",
      "model parameters: {'model__C': 1, 'model__gamma': 0.5, 'selector__k': 4}\n",
      "selected features: ['x0' 'x1' 'x2' 'x10']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.91      0.79       811\n",
      "           1       0.90      0.67      0.77       969\n",
      "\n",
      "    accuracy                           0.78      1780\n",
      "   macro avg       0.80      0.79      0.78      1780\n",
      "weighted avg       0.81      0.78      0.78      1780\n",
      "\n",
      "[[739  72]\n",
      " [322 647]]\n",
      "AUC = 0.789459686788597\n",
      "--------------Naive bayes features--------------\n",
      "model parameters: {'model__var_smoothing': 1e-08, 'selector__k': 3}\n",
      "selected features: ['x0' 'x1' 'x7']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.91      0.79       811\n",
      "           1       0.90      0.67      0.77       969\n",
      "\n",
      "    accuracy                           0.78      1780\n",
      "   macro avg       0.80      0.79      0.78      1780\n",
      "weighted avg       0.81      0.78      0.78      1780\n",
      "\n",
      "[[742  69]\n",
      " [322 647]]\n",
      "AUC = 0.7913092552226291\n",
      "--------------SVC rbf features & vect--------------\n",
      "model parameters: {'features__num__selector__k': 5, 'model__C': 1, 'model__gamma': 0.1}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.91      0.79       811\n",
      "           1       0.90      0.67      0.77       969\n",
      "\n",
      "    accuracy                           0.78      1780\n",
      "   macro avg       0.80      0.79      0.78      1780\n",
      "weighted avg       0.81      0.78      0.78      1780\n",
      "\n",
      "[[742  69]\n",
      " [322 647]]\n",
      "AUC = 0.7913092552226291\n",
      "--------------LogisticRegression features & vect--------------\n",
      "model parameters: {'features__num__selector__k': 4, 'model__C': 1}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.90      0.79       811\n",
      "           1       0.89      0.67      0.77       969\n",
      "\n",
      "    accuracy                           0.78      1780\n",
      "   macro avg       0.79      0.79      0.78      1780\n",
      "weighted avg       0.80      0.78      0.78      1780\n",
      "\n",
      "[[731  80]\n",
      " [315 654]]\n",
      "AUC = 0.788139475402076\n",
      "--------------Naive bayes features & vect--------------\n",
      "model parameters: {'features__num__selector__k': 4, 'model__var_smoothing': 1e-07}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.63      0.62       811\n",
      "           1       0.69      0.67      0.68       969\n",
      "\n",
      "    accuracy                           0.65      1780\n",
      "   macro avg       0.65      0.65      0.65      1780\n",
      "weighted avg       0.65      0.65      0.65      1780\n",
      "\n",
      "[[512 299]\n",
      " [318 651]]\n",
      "AUC = 0.6515729921016366\n",
      "--------------SVC rbf features + Logistic vect = Voting--------------\n",
      "model parameters: {'num_model__model__C': 1, 'num_model__model__gamma': 0.1, 'num_model__selector__k': 5, 'vect_model__model__C': 0.01}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.88      0.78       811\n",
      "           1       0.88      0.69      0.77       969\n",
      "\n",
      "    accuracy                           0.78      1780\n",
      "   macro avg       0.79      0.79      0.78      1780\n",
      "weighted avg       0.80      0.78      0.78      1780\n",
      "\n",
      "[[717  94]\n",
      " [303 666]]\n",
      "AUC = 0.785700106507656\n",
      "--------------SVC rbf features + Logistic vect = Stacking--------------\n",
      "model parameters: {'num_model__selector__k': 4}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.88      0.78       811\n",
      "           1       0.87      0.70      0.78       969\n",
      "\n",
      "    accuracy                           0.78      1780\n",
      "   macro avg       0.79      0.79      0.78      1780\n",
      "weighted avg       0.80      0.78      0.78      1780\n",
      "\n",
      "[[710 101]\n",
      " [292 677]]\n",
      "AUC = 0.7870604014206111\n",
      "--------------SVC rbf features + SVC rbf = Voting--------------\n",
      "model parameters: {'num_model__selector__k': 5}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.83      0.78       811\n",
      "           1       0.84      0.74      0.79       969\n",
      "\n",
      "    accuracy                           0.78      1780\n",
      "   macro avg       0.78      0.79      0.78      1780\n",
      "weighted avg       0.79      0.78      0.78      1780\n",
      "\n",
      "[[675 136]\n",
      " [252 717]]\n",
      "AUC = 0.7861219379048914\n",
      "--------------SVC rbf features + SVC rbf = Stacking--------------\n",
      "model parameters: {'num_model__selector__k': 5}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.89      0.79       811\n",
      "           1       0.88      0.70      0.78       969\n",
      "\n",
      "    accuracy                           0.79      1780\n",
      "   macro avg       0.80      0.80      0.79      1780\n",
      "weighted avg       0.81      0.79      0.79      1780\n",
      "\n",
      "[[722  89]\n",
      " [290 679]]\n",
      "AUC = 0.7954906669008054\n"
     ]
    }
   ],
   "source": [
    "evaluate_models(best_models, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "56d4d6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_noises, X_test_noises, y_train_noises, y_test_noises, get_num_noises, get_vect_noises = prepare_input(noises_data, test_size, emb, feature_cols, target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6b9af48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_grids_noises = [\n",
    "    (\n",
    "        'RandomForest vect',\n",
    "        PipelineBuilder(lambda : RandomForestClassifier(random_state=42), get_vect_noises).build(), \n",
    "        {\n",
    "            'model__criterion': GridSearchRanges.rf_criterion,\n",
    "            'model__max_depth': GridSearchRanges.tree_max_depth,\n",
    "            'model__n_estimators': GridSearchRanges.tree_n_estimators,\n",
    "        },\n",
    "        'accuracy'\n",
    "    ),\n",
    "    (\n",
    "        'GradientBoosting vect',\n",
    "        PipelineBuilder(lambda : GradientBoostingClassifier(random_state=42), get_vect_noises).build(), \n",
    "        {\n",
    "            'model__criterion': GridSearchRanges.gb_criterion,\n",
    "            'model__max_depth': GridSearchRanges.tree_max_depth,\n",
    "            'model__n_estimators': GridSearchRanges.tree_n_estimators,\n",
    "        },\n",
    "        'accuracy'\n",
    "    ),\n",
    "    (\n",
    "        'RandomForest features',\n",
    "        PipelineBuilder(lambda : RandomForestClassifier(random_state=42), get_num_noises).build(), \n",
    "        {\n",
    "            'model__criterion': GridSearchRanges.rf_criterion,\n",
    "            'model__max_depth': GridSearchRanges.tree_max_depth,\n",
    "            'model__max_features': GridSearchRanges.tree_max_features,\n",
    "            'model__n_estimators': GridSearchRanges.tree_n_estimators,\n",
    "        },\n",
    "        'accuracy'\n",
    "    ),\n",
    "    (\n",
    "        'GradientBoosting features',\n",
    "        PipelineBuilder(lambda : GradientBoostingClassifier(random_state=42), get_num_noises).build(), \n",
    "        {\n",
    "            'model__criterion': GridSearchRanges.gb_criterion,\n",
    "            'model__max_depth': GridSearchRanges.tree_max_depth,\n",
    "            'model__max_features': GridSearchRanges.tree_max_features,\n",
    "            'model__n_estimators': GridSearchRanges.tree_n_estimators,\n",
    "        },\n",
    "        'accuracy'\n",
    "    ),\n",
    "    (\n",
    "        'RandomForest features & vect',\n",
    "        PipelineBuilder(lambda : RandomForestClassifier(random_state=42), get_num_noises).use_vect(get_vect_noises).build(), \n",
    "        {\n",
    "            'model__criterion': GridSearchRanges.rf_criterion,\n",
    "            'model__max_depth': GridSearchRanges.tree_max_depth,\n",
    "            'model__n_estimators': GridSearchRanges.tree_n_estimators,\n",
    "        },\n",
    "        'accuracy'\n",
    "    ),\n",
    "    (\n",
    "        'GradientBoosting features & vect',\n",
    "        PipelineBuilder(lambda : GradientBoostingClassifier(random_state=42), get_num_noises).use_vect(get_vect_noises).build(), \n",
    "        {\n",
    "            'model__criterion': GridSearchRanges.gb_criterion,\n",
    "            'model__max_depth': GridSearchRanges.tree_max_depth,\n",
    "            'model__n_estimators': GridSearchRanges.tree_n_estimators,\n",
    "        },\n",
    "        'accuracy'\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e7b8701c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 6\n",
      "2 / 6\n",
      "3 / 6\n",
      "4 / 6\n",
      "5 / 6\n",
      "6 / 6\n"
     ]
    }
   ],
   "source": [
    "best_models_noises = get_best_models(pipeline_grids_noises, X_train_noises, y_train_noises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "397c57bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------RandomForest vect--------------\n",
      "model parameters: {'model__criterion': 'gini', 'model__max_depth': 6, 'model__n_estimators': 100}\n",
      "    feature  importance\n",
      "87      x87    0.034478\n",
      "16      x16    0.034204\n",
      "195    x195    0.027520\n",
      "39      x39    0.026322\n",
      "120    x120    0.024822\n",
      "184    x184    0.024251\n",
      "70      x70    0.022997\n",
      "291    x291    0.021720\n",
      "28      x28    0.019667\n",
      "268    x268    0.019082\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.53      0.57      1090\n",
      "           1       0.66      0.73      0.69      1355\n",
      "\n",
      "    accuracy                           0.64      2445\n",
      "   macro avg       0.63      0.63      0.63      2445\n",
      "weighted avg       0.64      0.64      0.64      2445\n",
      "\n",
      "[[573 517]\n",
      " [364 991]]\n",
      "AUC = 0.628526693523816\n",
      "--------------GradientBoosting vect--------------\n",
      "model parameters: {'model__criterion': 'friedman_mse', 'model__max_depth': 6, 'model__n_estimators': 100}\n",
      "    feature  importance\n",
      "87      x87    0.040281\n",
      "16      x16    0.029950\n",
      "120    x120    0.027981\n",
      "184    x184    0.026783\n",
      "39      x39    0.019689\n",
      "195    x195    0.018188\n",
      "117    x117    0.010738\n",
      "115    x115    0.006967\n",
      "135    x135    0.006940\n",
      "122    x122    0.006600\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.55      0.57      1090\n",
      "           1       0.66      0.70      0.68      1355\n",
      "\n",
      "    accuracy                           0.63      2445\n",
      "   macro avg       0.63      0.62      0.63      2445\n",
      "weighted avg       0.63      0.63      0.63      2445\n",
      "\n",
      "[[595 495]\n",
      " [402 953]]\n",
      "AUC = 0.6245962964216798\n",
      "--------------RandomForest features--------------\n",
      "model parameters: {'model__criterion': 'gini', 'model__max_depth': 6, 'model__max_features': 'log2', 'model__n_estimators': 200}\n",
      "   feature  importance\n",
      "0       x0    0.603531\n",
      "24     x24    0.075804\n",
      "16     x16    0.041694\n",
      "7       x7    0.026167\n",
      "2       x2    0.022153\n",
      "6       x6    0.021491\n",
      "13     x13    0.021089\n",
      "1       x1    0.020031\n",
      "4       x4    0.017807\n",
      "19     x19    0.016007\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.83      0.77      1090\n",
      "           1       0.84      0.74      0.79      1355\n",
      "\n",
      "    accuracy                           0.78      2445\n",
      "   macro avg       0.78      0.79      0.78      2445\n",
      "weighted avg       0.79      0.78      0.78      2445\n",
      "\n",
      "[[ 903  187]\n",
      " [ 350 1005]]\n",
      "AUC = 0.7850688919733233\n",
      "--------------GradientBoosting features--------------\n",
      "model parameters: {'model__criterion': 'squared_error', 'model__max_depth': 5, 'model__max_features': 6, 'model__n_estimators': 100}\n",
      "   feature  importance\n",
      "0       x0    0.541101\n",
      "24     x24    0.050087\n",
      "16     x16    0.038159\n",
      "6       x6    0.037738\n",
      "7       x7    0.026138\n",
      "12     x12    0.024198\n",
      "2       x2    0.023056\n",
      "15     x15    0.018656\n",
      "19     x19    0.018494\n",
      "13     x13    0.017207\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.81      0.77      1090\n",
      "           1       0.83      0.77      0.80      1355\n",
      "\n",
      "    accuracy                           0.79      2445\n",
      "   macro avg       0.78      0.79      0.79      2445\n",
      "weighted avg       0.79      0.79      0.79      2445\n",
      "\n",
      "[[ 879  211]\n",
      " [ 312 1043]]\n",
      "AUC = 0.7880818578827989\n",
      "--------------RandomForest features & vect--------------\n",
      "model parameters: {'model__criterion': 'entropy', 'model__max_depth': 6, 'model__n_estimators': 200}\n",
      "    feature  importance\n",
      "0        x0    0.294460\n",
      "146    x146    0.024625\n",
      "113    x113    0.022030\n",
      "210    x210    0.018754\n",
      "42      x42    0.018157\n",
      "221    x221    0.016589\n",
      "54      x54    0.016587\n",
      "65      x65    0.015827\n",
      "24      x24    0.015653\n",
      "96      x96    0.014520\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.64      0.69      1090\n",
      "           1       0.74      0.83      0.78      1355\n",
      "\n",
      "    accuracy                           0.74      2445\n",
      "   macro avg       0.74      0.73      0.73      2445\n",
      "weighted avg       0.74      0.74      0.74      2445\n",
      "\n",
      "[[ 695  395]\n",
      " [ 235 1120]]\n",
      "AUC = 0.7320914722908698\n",
      "--------------GradientBoosting features & vect--------------\n",
      "model parameters: {'model__criterion': 'friedman_mse', 'model__max_depth': 5, 'model__n_estimators': 150}\n",
      "    feature  importance\n",
      "0        x0    0.449650\n",
      "6        x6    0.016625\n",
      "12      x12    0.014509\n",
      "7        x7    0.011363\n",
      "2        x2    0.010619\n",
      "5        x5    0.010089\n",
      "113    x113    0.009289\n",
      "4        x4    0.006900\n",
      "25      x25    0.006405\n",
      "143    x143    0.006111\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.80      0.77      1090\n",
      "           1       0.83      0.77      0.80      1355\n",
      "\n",
      "    accuracy                           0.78      2445\n",
      "   macro avg       0.78      0.78      0.78      2445\n",
      "weighted avg       0.79      0.78      0.78      2445\n",
      "\n",
      "[[ 875  215]\n",
      " [ 316 1039]]\n",
      "AUC = 0.7847709807373302\n"
     ]
    }
   ],
   "source": [
    "evaluate_models(best_models_noises, X_test_noises, y_test_noises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af21a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline.set_params(**{ 'voting': 'hard'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
